<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
	<meta http-equiv="content-type" content="text/html; charset=windows-1252"/>
	<title>Subatomic Physics of Math: (Non)Classical Logic</title>
	<style type="text/css">
		@page { margin: 0.79in }
		p { margin-bottom: 0.1in; line-height: 120% }
		a:link { so-language: zxx }
		* {
            font-family: "Liberation Serif", serif
        }
	</style>
</head>
<body lang="en-US" dir="ltr">
<div style="position:fixed; top:0.5em; left:0.5em; background:white"><a href="./">Home</a> &gt; <a href="./SubatomicPhysicsOfMath.html">Set theory: notation</a></div>
<h1 align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 16px">Subatomic Physics of Math: (Non)Classical Logic</h1>
<span style="border: 1px solid black; display:block; float:right">
	<ol type="I">
		<li><a href="#origin">Summary of Bernays' starting point</a></li>
		<li><a href="#transitivity-of-implication">Transitivity of implication</a></li>
		<li><a href="#uniform-substitution">Uniform substitution</a></li>
		<li><a href="#relevance-roadmap-nonstrictly-implies">Relevance roadmap for &rArr;</a></li>
		<li><a href="#analogies-and-or">Analogies for &, and &#x2228;</a></li>
		<li><a href="#constructive-dilemma">Constructive Dilemma</a></li>
		<li><a href="#absorption">Absorption</a></li>
		<li><a href="#reductio-ad-absurdum">Proof by contradiction</a></li>
		<li><a href="#or-elimination">Or elimination</a></li>
		<li><a href="#contrapositive-1">Taking the contrapositive</a></li>
		<li><a href="#modus-tollens"><i>Modus Tollens</i></a></li>
		<li><a href="#modus-tollens-syntactical-entailment"><i>modus tollens</i> for &#9500;</a></li>
		<li><a href="#destructive-dilemma">Destructive Dilemma</a></li>
		<li><a href="#classical-law-of-contradiction">Classical Law of Contradiction</a></li>
		<li><a href="#exportation">Exportation</a></li>
		<li><a href="#de-morgan">De Morgan's Laws</a></li>
		<li><a href="#associativity-or">Associativity of &#x2228;</a></li>
		<li><a href="#modus-ponendo-tollens"><i>modus ponendo tollens</i></a></li>
		<li><a href="#distribuvity-or-and">Distributivity of &#x2228; with respect to &</a></li>
		<li><a href="#proof-by-cases">Proof by cases</a></li>
		<li><a href="#excluded-middle">Law of Excluded Middle</a></li>
		<li><a href="#translating-truth-tables">Translating to and from truth tables</a></li>
		<li><a href="#principle-of-explosion">Principle of explosion</a></li>
		<li><a href="#commutativity-or-lisp">Repairing commutativity of &#x2228; for Lisp/Prolog logic</a></li>
		<li><a href="#transitivity-of-iff">Transitivity of &hArr;</a></li>
		<li><a href="#commutativity-of-implication">Commutativity of Implication</a></li>
	</ol>
</span>	
<p id="origin">In <a href="https://archive.org/details/axiomaticsettheo0000bern">Axiomatic Set Theory</a>, Bernays mentions (hardcopy p.48, also digital p.48 in two-page view) how all 
of the inference schemas of predicate calculus are derivable from the usual undefined terminology and definitions, and a short summary:</p>
<ol>
	<li>Tautologies: i.e., formulas constructed out of propositional variables A,B,C,... and logical connectives such that no matter
		which truth values <i>true</i> and <i>false</i> are assigned to those variables, the formula evaluates to <i>true</i>.  (We expect no such formulas
		to exist for the non-classical logics.  Thus, the use of any tautology is a strong hint that the proof is specific to classical logic.)</li>
	<li>The four primary syntactical inference schemata for <a href="./SubatomicPhysicsOfMath.html#def-quantify">for <span style="transform:rotate(180deg);display:inline-block">A</span> and <span style="transform:rotate(180deg);display:inline-block">E</span>.</a></li>
	<li><i>Modus ponens</i></li>
</ol>
<p>As our text was strictly using classical logic, there was no good editorial reason to go further there.  To use logic as a parameter for set theory,
	we need to see how our reference non-classical logics vary from classical logic.  We summarize the second and third points as:</p>
<table align="center">
<tr><th></th><th>Name</th><th></th></tr>
<tr align="center"><td>(<span style="transform:rotate(180deg);display:inline-block">E</span>a)Z(a) := ~((<span style="transform:rotate(180deg);display:inline-block">A</span>a)~Z(a))</td><td></td><td>a is a bound variable due to the quantifier</td></tr>
<tr align="center"><td>(<span style="transform:rotate(180deg);display:inline-block">A</span>a)Z(a) &#9500; Z(t)</td><td>Universal instantiation</td><td>Z(a) may have implicitly used term t</td></tr>
<tr align="center"><td>Z(t) &#9500; (<span style="transform:rotate(180deg);display:inline-block">E</span>a)Z(a)</td><td>Existential generalization</td><td><i>Z(t)</i>, and all notationally prior statements to <i>Z(t)</i>, must not have used symbol <i>a</i></td></tr>
<tr align="center"><td>P &rArr; Z(t) &#9500; P &rArr; (<span style="transform:rotate(180deg);display:inline-block">A</span>a)Z(a)</td><td>Universal generalization</td><td><i>P &rArr; Z(t)</i>, and all notationally prior statements to <i>P &rArr; Z(t)</i>, must not have used symbol <i>a</i></td></tr>
<tr align="center"><td>Z(t) &rArr; P &#9500; (<span style="transform:rotate(180deg);display:inline-block">E</span>a)Z(a) &rArr; A</td><td>Existential generalization</td><td><i>Z(t) &rArr; P</i>, and all notationally prior statements to <i>Z(t) &rArr; P</i>, must not have used symbol <i>a</i></td></tr>
<tr align="center"><td>P, P &rArr; Q &#9500; Q</td><td><i>modus ponens</i></td><td></td></tr>
</table>
<p>In the above:</p>
<ul>
<li>The domain of discourse which the existential and universal quantifiers range over, is implicit.  For a many sorted formal system, some method of tracking which domain of discourse any given
	quantifier ranges over, is needed; we'll use a combination of natural language and formal notation.</li>
<li>P and Q are propositional variables, i.e. truth-valued variables, with an arbitrary given expansion into either natural language, or a formal-system formula.</li>
<li><i>t</i> is a term in the domain of discourse, referenced implicitly by the quantifier elsewhere in the expression.  We could use any symbol in place of t, that is used nowhere else.</li>
<li>Z(...) is a syntactically truth-valued formula using an explicit parameter (and possibly implicit parameters not stated).  Recall that to actually have a truth value, the formula must not
	not contain any free variables.  (Free variables, may be thought of as variables not associated with a domain of discourse.)</li>
<li>At this level, we don't have the formal machinery to notate that a formula, or non-atomic term, does <b>not</b> use a named term or variable.</li>
<li>We can view <i>modus ponens</i> as either a common semantic consequence of each of the six logics we are considering, or an axiom about syntactical entailment.</li>
<li>We do not yet have the formal machinery to handle recovering from inconsistent assertions &mdash; i.e., we're not considering paraconsistent logic,
	even though two of our nonclassical logics have <i>contradiction</i> as a truth value.</li>
<li>We also do not yet have the formal machinery to handle proof existence.  That is, we are not going to consider Intuitionistic logic in detail.
	The intended interpretation for Intuitionistic syntactical entailment, is proof existence; this is also known as the Brouwer-Heyting-Kolmogorov
	interpretation.</li>
<li>We are not going to handle, at all, problems with inaccurate translation from natural language to formal notation.  That is,
	we are not going to consider either defeasible logic, or relevance logic, in detail.</li>
<li>More generally, this is a "cheat sheet" -- almost all of the terminology I introduce here, should be very standard with reasonable
	search engine results.  Any non-standard terminology intentionally introduced, shall have a yellow background.</li>
</ul>
<p>What we <b>are</b> following instructions for, is how to build out the formal infrastructure for representing all of Intuitionistic logic,
	the various approaches to paraconsistent logic, the various approaches to defeasible logic, and the various approaches to relevance logic.
	I will include some commentary about what parts of classical logic fail for these.  However, I am using close to the <b>minimum known possible</b>
	undefined terminology here. I'm expecting everything needed for these, to be formally definable in terms of what we're looking at here.</p>
<a href="./LogicFormalization.dot.svg" target="_blank"><img src="./LogicFormalization.dot.svg" width="100%" alt="map of logic"></a>
<h2 id="transitivity-of-implication" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Transitivity of implication</h2>
<p>As our first example of a conditional proof, let's formally calculate <i>transitivity of implication</i> for three propositional variables P, Q, R:</p>
<p align="center">P &rArr; Q, Q &rArr; R &#9500; P &rArr; R</p>
<p>We'll use a table-based layout, instead of an ordered list.  The actual <a href="https://en.wikipedia.org/wiki/Hypothetical_syllogism">calculation</a>, is notated in the second column.</p>
<table align="center">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &rArr; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>Q &rArr; R</td><td>Given</td></tr>
	<tr><td>3.</td><td>P</td><td>Hypothesis</td></tr>
	<tr><td>4.</td><td>Q</td><td><i>modus ponens</i> on (1) and (3)</td></tr>
	<tr><td>5.</td><td>R</td><td><i>modus ponens</i> on (2) and (4)</td></tr>
	<tr><td>6.</td><td>P &rArr; R</td><td>Implication introduction, (3) and (5)</td></tr>
</table>
<p>The above table documents a formal calculation that the <i>transitivity of implication</i> syntactical entailment, 
	is derivable i.e. provable from <i>modus ponens</i>. The third column is a terse mnemonic that in principle can 
	be expanded into full sentences.  That is, we can translate the above table into a (much longer) English-wrapped conditional proof.
	In the tabular representation for conditionally proving a syntactical entailment:</p>
<ul>
	<li>The syntactically entailed statement is always the last row.</li>
	<li>The hypothesis statements of the syntactical entailment, are the first rows in the table.  They are labeled "Given" and are 
		assumed to be possible to evaluate to the truth value <i>true</i>.  A statement labeled Given, whose truth value cannot evaluate to <i>true</i>,
		results in a syntactically reasonable yet invalid formal calculation.  This is critical for Implication Introduction to work
		for the truth table describable non-classical logics we are considering.</li>
	<li>The remaining table rows, are roughly in reverse order of how one would do the formal calculation by textual substitions.</li>
</ul>
<p>Other names for <i>transitivity of implication</i> are "hypothetical syllogism" (abbreviated HS), "chain argument", or the exceedingly generic "chain rule".</p>
<p>The hypotheses to be tested for the conditional proof technique, can be read off of <i>modus ponens</i>: they're
	the missing hypotheses of the <i>modus ponens</i> instances.  We had two candidate hypotheses, A and B.  However, B was
	the result of one of the <i>modus ponens</i> instances, while A could not be obtained that way.</p>
<p>Also, we could replace the given <i>P &rArr; Q</i> and its matching <i>modus ponens</i> use, with the syntactical entailment rule <i>P &#9500; Q</i> .  Likewise, we could replace the given <i>Q &rArr; R</i> and its matching <i>modus ponens</i> use, with the syntactical entailment rule <i>Q &#9500; R</i> .  Notating this 
is tricky, as syntactical entailment rules are not truth-valued.  In the absence of a proper authority, I'll extend the syntactical entailment notation by wrapping entailment rules 
in parentheses.  The non-standard parts of the following table, have background color yellow.</p>

<p>The above proof, is invalid for Belnap's four-valued logic(!).  To verify this, let <i>P</i> and <i>R</i> have truth value <i>contradiction</i> and <i>Q</i> have truth value <i>unknown</i>.  It is
	then a mechanical exercise that <i>P &rArr; Q</i> and <i>Q &rArr; R</i> both evaluate to <i>true</i>, yet <i>P &rArr; R</i> evaluates to their common truth value <i>contradiction</i>.</p>
<p>Let us introduce some terminology.  For a nonstrict implication <i>A &rArr; B</i>, we say:</p>
<ul>
<li><i>A</i> is the hypothesis of <i>A &rArr; B</i>.  Alternately, <i>A</i> is the antecedent of <i>A &rArr; B</i>.</li>
<li><i>B</i> is the conclusion of <i>A &rArr; B</i>.  Alternately, <i>A</i> is the consequence of <i>A &rArr; B</i>.</li>
</ul>
<p>Likewise, for a syntactical entailment <i>A &#9500; B</i>, we say:</p>
<ul>
<li><i>A</i> is the hypothesis of <i>A &#9500; B</i>.</li>
<li><i>B</i> is the conclusion of <i>A &#9500; B</i>.</li>
</ul>
<p>From the truth table description of &rArr;, it appears the problem is that for the non-classical logics, we don't actually know that
	the Hypothesis step, and the reached Conclusion step, do not have non-classical truth values. (This choice of phrasing, is to allow for Intuitionistic logic.)
	There may be other problems as well.  For now, we will treat <i>implication introduction</i> as valid for classical logic,
	but not any of the truth table described non-classical logics we are considering.</p>
<p>Once we have verified the analogies that allow translating a truth table verification of a propositional calculus inference rule, to a symbolic logic verification of said 
	inference rule, the exercise of verifying <i>transitivity of implication</i> (or lack thereof) for all five truth table-described nonclassical logics 
	can be done.  (This verification will be classical logic reasoning about a given non-classical logic.)</p>
<table align="center">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &rArr; Q, Q &rArr; R &#9500; P &rArr; R</td><td align="left">Transitivity of implication</td><td align="left">Belnap</td><td>Defeasible logics</td></tr>
	<tr><td align="center" style="background: yellow">(P &#9500; Q), Q &rArr; R &#9500; P &rArr; R</td><td align="left" style="background: yellow">Invert using P &#9500; Q on the hypothesis of Q &rArr; R</td><td align="left">Belnap</td><td>Defeasible logics</td></tr>
	<tr><td align="center" style="background: yellow">P &rArr; Q, (Q &#9500; R)  &#9500; P &rArr; R</td><td align="left" style="background: yellow">Using Q &#9500; R on the conclusion of P &rArr; Q</td><td align="left">Belnap</td><td>Defeasible logics</td></tr>
</table>
<p>The general issue defeasible logics have with <i>transitivity of implication</i>, is that in natural language we omit many "default hypotheses". 
that is, a plain English statement describing a (semantic) implication, often has a much larger formal expansion than a direct interpretation would suggest.
This is <b>not</b> a problem for the level of mathematics, that we are following instructions for building out.  (This also means defeasible logics have issues either
with <i>modus ponens</i> itself, or the conditional proof formalism as a justification for implication introduction.)</p>
<p>A philosophical problem with the non-standard notation I introduced above, is that strictly speaking an inference rule is not a truth-valued statement.  We would like to
think of an inference rule as a function, with domain and range statements.  (None of "function", "domain", or "range" have been formally defined, at this point.)  That is, if we were to 
consider a standard inference rule using &#9500; to be "first order with domain of discourse statements", then the extended notation inference rules in
the above table would be "second order with domain of discourse statements": these use variables that range over inference rules, rather than statements i.e. truth-valued expressions.</p>
<p>Considering that our text predates the Gentzen-style notation, it appears that we can take an alternate form of <i>modus ponens</i> as axiomatic:</p>
<table align="center">
	<tr><th></th><th>Name</th><th></th></tr>
	<tr align="center"><td>P, (P &#9500; Q) &#9500; Q</td><td><i>modus ponens</i> (for &#9500;)</td><td></td></tr>
</table>
The corresponding proof would then be:
<table align="center">
	<tr><th></th><th>Inference rule</th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &#9500; Q</td><td></td><td>Given</td></tr>
	<tr><td>2.</td><td>Q &#9500; R</td><td></td><td>Given</td></tr>
	<tr><td>3.</td><td></td><td>P</td><td>Hypothesis</td></tr>
	<tr><td>4.</td><td></td><td>Q</td><td><i>modus ponens</i> on (1) and (3)</td></tr>
	<tr><td>5.</td><td></td><td>R</td><td><i>modus ponens</i> on (2) and (4)</td></tr>
	<tr><td>6.</td><td>P &#9500; R</td><td></td><td><span style="background:yellow">Syntactical entailment introduction</span>, (3) and (5)</td></tr>
</table>
<p>The more typical name for this, is the cut rule.  We have three other variations with very similar proofs:</p>
<table align="center">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center" style="background: yellow">(P &#9500; Q), (Q &#9500; R) &#9500; (P &#9500; R)</td><td align="left"><span style="background:yellow">Transitivity of syntactical entailment</span>, i.e. cut rule</td><td align="left">None</td><td>Defeasible logics</td></tr>
	<tr><td align="center" style="background: yellow">(P &#9500; Q), Q &rArr; R &#9500; (P &#9500; R)</td><td align="left" style="background: yellow">Using Q &rArr; R on the conclusion of P &#9500; Q</td><td align="left">None</td><td>Defeasible logics</td></tr>
	<tr><td align="center" style="background: yellow">P &rArr; Q, (Q &#9500; R) &#9500; (P &#9500; R)</td><td align="left" style="background: yellow">Invert using P &rArr; Q on the hypothesis of Q &#9500; R</td><td align="left">None</td><td>Defeasible logics</td></tr>
	<tr><td align="center" style="background: yellow">P &rArr; Q, Q &rArr; R &#9500; (P &#9500; R)</td><td align="left"><span style="background:yellow"></td><td align="left">None</td><td>Defeasible logics</td></tr>
</table>
<p>We also have transitivity of syntactical equivalence, as follows:</p>
<table align="center">
	<tr><th></th><th>Inference Rule</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>A &#x27DB; B</td><td>Given</td></tr>
	<tr><td>2.</td><td>B &#x27DB; C</td><td>Given</td></tr>
	<tr><td>3.</td><td>A &#9500; B</td><td>Definition of &#x27DB; on (1)</td></tr>
	<tr><td>4.</td><td>B &#9500; C</td><td>Definition of &#x27DB; on (2)</td></tr>
	<tr><td>5.</td><td>A &#9500; C</td><td>Transitivity of syntactical entailment on (3), (4)</td></tr>
	<tr><td>6.</td><td>B &#9500; A</td><td>Definition of &#x27DB; on (1)</td></tr>
	<tr><td>7.</td><td>C &#9500; B</td><td>Definition of &#x27DB; on (2)</td></tr>
	<tr><td>8.</td><td>C &#9500; A</td><td>Transitivity of syntactical entailment on (6), (7)</td></tr>
	<tr><td>9.</td><td>A &#x27DB; B</td><td>Definition of &#x27DB; on (5), (8)</td></tr>
</table>
<table align="center">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center" style="background: yellow">(A &#x27DB; B), (B &#x27DB; C) &#9500; (A &#x27DB; C)</td><td align="left">Transitivity of syntactical equivalence</td><td align="left">None</td><td>Defeasible logics</td></tr>
</table>
<p>Exercise: demonstrate the following.  (Both of these follow from the axiomatic identity inference rule <i>A &#9500; A</i>.)</p>
<table align="center">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">A &#x27DB; A</td><td align="left">Reflexivity of syntactical equivalence</td><td align="left">None</td><td>None</td></tr>
	<tr><td align="center" style="background: yellow">(A &#x27DB; B) &#x27DB; (B &#x27DB; A)</td><td align="left">Commutativity of syntactical equivalence</td><td align="left">None</td><td>None</td></tr>
</table>

<h2 id="uniform-substitution" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Uniform substitution</h2>
<p><a href="https://www.planetmath.org/substitutionsinpropositionallogic">Uniform substitutions</a> are central to the notational manipulations of mathematics.  Since one of
my objectives here, is to identify which set theories <b>can</b> mathematically model notation without the assistance of an intended interpretation, we shall just describe
rather than define how uniform substitutions work.</p>
<p>For three truth-valued expressions A, B, C, applying A &#x21A6; B to C has the intended interpretation that B is to be globally substituted for A in the expression C,
	resulting in a truth-valued expression C[B/A].  We have the following desired properties:</p>
<ul>
	<li>Since truth values are undefined, they contain no subexpressions.  We expect applying A &#x21A6; B to any given truth value, where A is not the given truth value itself,
		to result in the same truth value.</li>
	<li>For any two truth-valued expressions A, B, we expect B[A/A] to be B.</li>
	<li>For any non-truth-valued expression b in a given universe of discourse, we expect A[b/b] to be A regardless of whether A is a truth-valued expression, or an expression 
		in a (possibly different) universe of discourse.</li>
	<li>For a propositional variable A and truth-valued expression B, we expect A[B/A] to be B.  If B does not use A, we expect B[A/B] to be A.  If in addition, 
		the truth valued expression C does not use either A or B, we expect C[B/A][A/B] to be C.</li>
	<li>For a variable b in a universe of discourse, and an expression c with a value in the same universe of discourse, we expect b[c/b] to be c.  If c does not use the variable b, we expect c[b/c] to be b.</li>
	<li>For truth-valued expressions A, B: we expect (~A)[B/~A] to be B.  We expect (~A)[B/A] to be ~B.  When a truth-valued expression C is known to not be either A or ~A,
		we expect (~C)[B/A] to be ~(C[B/A]).</li>
	<li>For truth-valued expressions A, B, C, D: we expect (C & D)[B/C & D] to be B.  If A is known not to be C & D, we expect (C & D)[B/A] to be C[B/A] & D[B/A].</li>
	<li>For truth-valued expressions A, B, C, D: we expect (C &#x2228; D)[B/C &#x2228; D] to be B.  If A is known not to be C &#x2228; D, we expect (C &#x2228; D)[B/A] to be C[B/A] &#x2228; D[B/A].</li>
	<li>For truth-valued expressions A, B, C, D: we expect (C &#9500; D)[B/A] to be C[B/A] &#9500; D[B/A] .  If (C &#9500; D) is a valid inference rule and [B/A] a uniform substitution replacing a propositional variable A, we 
		expect (C &#9500; D)[B/A] to be a valid inference rule.</li>
	<li>We have similar expectations for predicates taking terms as parameters, as for the undefined logical connectives ~, &, &#x2228; above.</li>
	<li>In general, a uniform substitution that replaces a term, term variable or propositional variable with an expression, leaves all instances of <b>other</b> terms, term variables, and propositional variables unchanged.
		This is key to describing simultaneous uniform substitutions C[B/A,E/D, ...] correctly.</li>
</ul>
<p>A definition A := B is enough to justify either [A/B] or [B/A] as valid uniform substitutions, or as an entry in a simultaneous substitution.</p>
<p>If A evaluates to a given truth value B, then it is very tempting to say, for a truth-valued expression C, that applying A &#x21A6; B to C partially evaluates C.  In particular,
	if we allow the following expressions to have truth values, for the logics in which the given truth values are used:</p>
<ul>
	<li>A &#x21A6; <i>true</i>, with intended interpretation "A evaluates to <i>true</i>", or "A is <i>true</i>".</li>
	<li>A &#x21A6; <i>false</i>, with intended interpretation "A evaluates to <i>false</i>", or "A is <i>false</i>".</li>
	<li>A &#x21A6; <i>unknown</i>, with intended interpretation "A evaluates to <i>unknown</i>".</li>
	<li>A &#x21A6; <i>contradiction</i>, with intended interpretation "A evaluates to <i>contradiction</i>".</li>
</ul>
<p>We then can translate the truth-table descriptions of the logics we are considering, into (classical) logic.  In particular, the intended interpretations semantically entail the syntactical equivalences</p>
<table align="center">
	<tr><th colspan="2"></th><th>Name</th></tr>
	<tr><td align="right">B &#x27DB;&nbsp;</td><td>B[A &#x21A6; <i>true</i>/A]</td><td rowspan="4"><span style="background:yellow">Intended interpretation of &#x21A6;</span></td></tr>
	<tr><td align="right">A &#x27DB;&nbsp;</td><td>A &#x21A6; <i>true</i></td></tr>
	<tr><td align="right">B &#x27DB;&nbsp;</td><td>B[A &#x21A6; <i>false</i>/~A]</td></tr>
	<tr><td align="right">~A &#x27DB;&nbsp;</td><td>A &#x21A6; <i>false</i></td></tr>
	<tr><td align="right">(A &#9500; B) &#x27DB;&nbsp;</td><td>((A &#x21A6; <i>true</i>) &#9500; (B &#x21A6; <i>true</i>))</td><td rowspan="2">Special cases of note</td></tr>
	<tr><td align="right">A &#x21A6; <i>true</i> &#x27DB;&nbsp;</td><td>(A &#x21A6; <i>true</i>) &#x21A6; <i>true</i></td></tr>
	<tr><td align="right">(A &#9500; B) &#x27DB;&nbsp;</td><td>(&#9500; (A &#x21A6; <i>true</i>) &rArr; (B &#x21A6; <i>true</i>))</td><td><span style="background:yellow">Intended interpretation of &#x21A6;</span>; left side may be a non-classical inference rule, right side is a classical logic inference rule(!)</td></tr>
</table>
<p>The last row, as written, could induce notational ambiguity in a proof written for a non-classical logic.  For now, we'll have to be careful in the rationale comments.</p>
<!-- \todo identify a good notational convention, for a statement that is using a forced logic -->
<p>These syntactical equivalences in general do <b>not</b> justify uniform substitutions.  This will be more evident, when we use this notation to translate truth table descriptions into 
	symbolic logic descriptions of the logical connectives.  We expect, from the intended interpretation, the following syntactical entailments:</p>
<table align="center">
	<tr><th colspan="2"></th><th>Name</th></tr>
	<tr><td align="right">A &#x21A6; <i>true</i>, B &#9500;&nbsp;</td><td>B[<i>true</i>/A]</td><td rowspan="4"><span style="background:yellow">Partial evaluation of B</span></td></tr>
	<tr><td align="right">A &#x21A6; <i>false</i>, B &#9500;&nbsp;</td><td>B[<i>false</i>/A]</td></tr>
	<tr><td align="right">A &#x21A6; <i>unknown</i>, B &#9500;&nbsp;</td><td>B[<i>unknown</i>/A]</td></tr>
	<tr><td align="right">A &#x21A6; <i>contradiction</i>, B &#9500;&nbsp;</td><td>B[<i>contradiction</i>/A]</td></tr>
</table>
<table align="left">
<tr><th colspan="3">Principle of non-contradiction</th>
<tr><th rowspan="2" style="background: #DDFFDD">Classical</th><td align="right">(A &#x21A6; <i>true</i>) &#9500;&nbsp;</td><td>~(A &#x21A6; <i>false</i>)</td></tr>
<tr><td align="right">(A &#x21A6; <i>false</i>) &#9500;&nbsp;</td><td>~(A &#x21A6; <i>true</i>)</td></tr>
<tr><th rowspan="3" style="background: #DDDDFF">Kleene weak<br>Kleene strong<br>Lisp/Prolog</th><td align="right">(A &#x21A6; <i>true</i>) &#9500;&nbsp;</td><td>~(A &#x21A6; <i>false</i>) & ~(A &#x21A6; <i>unknown</i>)</td></tr>
<tr><td align="right">(A &#x21A6; <i>false</i>) &#9500;&nbsp;</td><td>~(A &#x21A6; <i>true</i>) & ~(A &#x21A6; <i>unknown</i>)</td></tr>
<tr><td align="right">(A &#x21A6; <i>unknown</i>) &#9500;&nbsp;</td><td>~(A &#x21A6; <i>true</i>) & ~(A &#x21A6; <i>false</i>)</td></tr>
<tr><th rowspan="4" style="background: #FFDDDD">Belnap<br>Franci</th><td align="right">(A &#x21A6; <i>true</i>) &#9500;&nbsp;</td><td>~(A &#x21A6; <i>false</i>) & ~(A &#x21A6; <i>unknown</i>) & ~(A &#x21A6; <i>contradiction</i>)</td></tr>
<tr><td align="right">(A &#x21A6; <i>false</i>) &#9500;&nbsp;</td><td>~(A &#x21A6; <i>true</i>) & ~(A &#x21A6; <i>unknown</i>) & ~(A &#x21A6; <i>contradiction</i>)</td></tr>
<tr><td align="right">(A &#x21A6; <i>unknown</i>) &#9500;&nbsp;</td><td>~(A &#x21A6; <i>true</i>) & ~(A &#x21A6; <i>false</i>) & ~(A &#x21A6; <i>contradiction</i>)</td></tr>
<tr><td align="right">(A &#x21A6; <i>contradiction</i>) &#9500;&nbsp;</td><td>~(A &#x21A6; <i>true</i>) & ~(A &#x21A6; <i>false</i>) & ~(A &#x21A6; <i>unknown</i>)</td></tr>
</td></tr>
</table>
<table align="right">
	<tr><th colspan="3">Principle of ...</th>
	<tr><th style="background: #DDFFDD">Classical</th><th>bivalence</th><td>&#9500; (A &#x21A6; <i>false</i>) &#x2228; (A &#x21A6; <i>true</i>)</td></tr>
	<tr><th style="background: #DDDDFF">Kleene weak<br>Kleene strong<br>Lisp/Prolog</th><th>trivalence</th><td>&#9500; (A &#x21A6; <i>false</i>) &#x2228; (A &#x21A6; <i>true</i>) &#x2228; (A &#x21A6; <i>unknown</i>)</td></tr>
	<tr><th rowspan="4" style="background: #FFDDDD">Belnap<br>Franci</th><th>tetravalence</th><td>&#9500; (A &#x21A6; <i>false</i>) &#x2228; (A &#x21A6; <i>true</i>) &#x2228; (A &#x21A6; <i>unknown</i>) &#x2228; (A &#x21A6; <i>contradiction</i>)</td></tr>
</table>
<p>The principle of non-contradiction (that no truth-valued expression may evaluate to two truth values at once) and the classical logic principle of bivalence (that all truth valued expressions do have a value) also have translations 
	into this extended notation.  (Natural language reasoning doesn't fully implement the principle of bivalence: otherwise, the liar paradox could not be stated.)</p>
<p>The other five truth table describable logics we are considering, all have analogous expressions.  The <i>principle of non-contradiction</i> looks like it has two consequences:</p>
<ul style="clear:left">
	<li>If a propositional variable evaluates to a given truth value (truth value of A &#x21A6;  ... <i>true</i>), then it does not evaluate to any of the other truth values (A &#x21A6; ___ <i>false</i>).</li>
	<li>If any of the A &#x21A6;  ... expressions has a classical truth value, all of them do.</li>
</ul>
<table align="right">
	<tr><th colspan="4">Classical logic</th></tr>
	<tr><th></th><th>Inference rule</th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>A &#9500; B</td><td></td><td>Given</td></tr>
	<tr><td>2.</td><td></td><td>A</td><td>Hypothesis</td></tr>
	<tr><td>3.</td><td></td><td>B</td><td>syntactical inference on (1),(2)</td></tr>
	<tr><td>4.</td><td></td><td>A &rArr; B</td><td>implication introduction on (2),(3)</td></tr>
</table>
<table align="left">
	<tr><th></th><th>Inference rule</th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td></td><td>A &rArr; B</td><td>Given</td></tr>
	<tr><td>2.</td><td></td><td>A</td><td>Hypothesis</td></tr>
	<tr><td>3.</td><td></td><td>B</td><td><i>modus ponens</i> on (1), (2)</td></tr>
	<tr><td>4.</td><td>A &#9500; B</td><td></td><td><span style="background:yellow">Syntactical entailment introduction</span>, (2) and (3)</td></tr>
</table>
<p>For classical logic <b>only</b>, we have a downgrade procedure from &#9500; to &rArr; .  The upgrade procedure is more reliable; it uses <i>syntactical entailment introduction</i>.  Proving the &hArr; versions from the &rArr; versions is 
left as an exercise.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Works for which logics?</th></tr>
	<tr><td align="center">(A &#9500; B) &#9500; (&#9500; A &rArr; B)</td><td><span style="background:yellow">Downgrade &#9500; to &rArr;</span></td><td>Classical</td></tr>
	<tr><td align="center">(A &#x27DB; B) &#9500; (&#9500; A &hArr; B)</td><td><span style="background:yellow">Downgrade &#x27DB; to &hArr;</span></td><td>Classical</td></tr>
	<tr><td align="center">A &rArr; B &#9500; (A &#9500; B)</td><td><span style="background:yellow">Upgrade &rArr; to &#9500;</span></td><td>All six</td></tr>
	<tr><td align="center">A &hArr; B &#9500; (A &#x27DB; B)</td><td><span style="background:yellow">Upgrade &hArr; to &#x27DB;</span></td><td>All six</td></tr>
</table>
<p>This shows what broke for Belnap's four-valued logic, when trying to prove <i>transitivity of implication</i>.  What was actually proved was:</p>
<p align="center">P &rArr; Q, Q &rArr; R &#9500; (P &#9500; R)</p>
<p>P &#9500; R was then downgraded to P &rArr; R.  So at this point, we only have <i>transitivity of implication</i> for classical logic.</p>
<p>It will also be convenient to say that the equality operator = is defined for any pair of truth values (but <b>not</b> arbitrary truth-valued expressions), with the usual properties expected (reflexivity, symmetry, transitivity).
For two truth-valued expressions A and B, if whenever A evaluates to a truth value, B evaluates to the same truth value as A, that justifies [B/A] as a valid uniform substitution, or as an entry in a non-uniform substitution.</p>
<p>However, a syntactic equivalence C &#x27DB; D only guarantees that (classically) (C &#x21A6; <i>true</i>) &hArr; (D &#x21A6; <i>true</i>); this is not enough to justify a substitution in general.  However, this is sufficient to justify a substitution for classical logic.</p>
<p>We also have a concept of non-uniform substitution, where different instances of the same syntactical expression are replaced by different substitutions.  The trivial 
	syntactical equivalence <i>A</i> &#x27DB; <i>A</i>, will be of some use with non-uniform substitutions.</p>
<p>We now have enough notation to <a href="./Reference_Logic.html">translate</a> truth tables into symbolic notation.</p>

<h2 id="relevance-roadmap-nonstrictly-implies" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Relevance roadmap for &rArr;</h2>
<table align="left">
<tr><th></th><th>Hypotheses for &#9500;</th><th>Rationale</th><th>Used for</th></tr>
<tr valign="top"><td>1.</td><td>P &rArr; Q, R &rArr; S</td><td>No relevance baseline</td><td>Constructive dilemma<br>destructive dilemma</td></tr>
<tr><td>2.</td><td>P &rArr; Q, Q &rArr; R</td><td>(1.)[Q/R, R/S]</td><td>Transitivity of implication</td></tr>
<tr><td>3.</td><td>P &rArr; Q, P &rArr; R</td><td>(1.)[P/R, R/S]</td><td></td></tr>
<tr><td>4.</td><td>P &rArr; Q, R &rArr; Q</td><td>(1.)[Q/S]</td><td>Proof by cases</td></tr>
<tr><td>5.</td><td>P &rArr; Q, P &rArr; ~Q</td><td>(3.)[~Q/R]</td><td>Classical law of contradiction</td></tr>
</table>	
<table align="right">
<tr><th></th><th>Hypothesis for &#9500;</th><th>Rationale</th><th>Used for</th></tr>
<tr><td>1.</td><td>P &rArr; Q</td><td>No relevance baseline</td><td></td></tr>
<tr><td>2.</td><td>P &rArr; ~P</td><td>(1.)[~P/Q]</td><td>Proof by contradiction</td></tr>
<tr><td>3.</td><td>P &rArr; P</td><td>(1.)[P/Q]</td><td>Law of Excluded Middle</td></tr>
</table>	
<p>One rationale for re-inventing <i>transitivity of implication</i>, would be to look at the syntactical axiom <i>modus ponens</i> Bernays said to assume,
	and consider ways to introduce relevance between two instances of &rArr;.  I have listed some examples, and where we will reach them.</p>
	
<h2 id="analogies-and-or" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px; clear:both">Analogies for "logical and" &, and "logical or" &#x2228;</h2>
<p>Classical logic's "logical and" & is closely related to the semantic entailment listing of hypotheses.  The five non-classical logics
	we are considering, all act like classical logic in that "logical and" & is defined so that the only way to get <i>P & Q</i> to be <i>true</i>, is for both
	<i>P</i> and <i>Q</i> to be <i>true</i>.  So we would expect to be able to prove that the single propositional calculus statement <i>P & (P &rArr; Q)</i>, allows using
	<i>modus ponens</i> to conclude <i>Q</i> by syntactical entailment.</p>
<p>Likewise, classical logic's "logical or" &#x2228; looks like the sort of statement we would not want to unnecessarily
	retain in a minimum collection or listing of statements to be retained in long-term memory.  That is, we would expect to be able to prove that knowing the single 
	propositional calculus statement <i>P</i>, allows concluding <i>P &#x2228; Q</i> for an arbitary propositional variable <i>Q</i>.</p>
<p>All six of the truth-functional logics we are considering, have only one combination, i.e. ordered pair, of truth values for which logical and & evaluates to <i>true</i>:</p>
<p align="center"><i>true</i> & <i>true</i> &#x21A6; <i>true</i></p>
<p>Which we expect, by intended interpretations of &#x21A6; and &#9500;, to translate to</p>
<p align="center">(P &#x21A6; <i>true</i>) & (Q &#x21A6; <i>true</i>) &#x27DB; (P & Q &#x21A6; <i>true</i>)</p>
<p>We are using syntactical equivalence &#x27DB; rather than syntactical entailment &#9500;, as there was exactly one row in the truth table 
	where P & Q evaluated to <i>true</i>.  In general, each row has its its own "forward" &#9500; rule, and the "reverse" rule can be a proper 
	sequent calculus rule, with one clause on the right hand side for each row.  The intended interpretation of A &#x21A6; <i>true</i>
	then gives the syntactical equivalence</p>
<p align="center">P, Q &#x27DB; P & Q</p>
<p>This is known as <i>conjunction introduction</i>.  We can think of the truth-table description as authorizing the following non-uniform substitution:</p>
<p align="center">(<i>true</i> & <i>true</i> &#x21A6; <i>true</i>)[(P, Q, P & Q),(<i>true</i>, <i>true</i>, <i>true</i>)]</p>
<p>The notation is intricate, as a non-uniform substitution must describe what to substitute for each instance.</p>
<p>Generalizing the procedure of condensed detachment, the corresponding syntactical entailment rules are <i>conjunction introduction</i> and <i>conjunction elimination</i>:</p>
<table align="center">
	<tr><th>Rationale</th><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td valign="top" rowspan="3">interpreting truth-table description</td><td align="center">P,Q &#x27DB; P & Q</td><td>Conjunction introduction</td><td align="left" valign="top" rowspan="5">None</td><td valign="top" rowspan="5">None</td></tr>
	<tr><td align="center">P & Q &#9500; P</td><td align="left" valign="top" rowspan="2">Conjunction elimination</td></tr>
	<tr><td align="center">P & Q &#9500; Q</td></tr>
	<tr><td>(P & Q &#9500; P)[P/Q]<br>(P & Q &#9500; Q)[P/Q]</td><td valign="top" align="center">P & P &#9500; P</td><td valign="top">Idempotence of &</td></tr>
</table>
<p>The intended interpretation of the left hand side of &#9500; , gives the following structural rules for truth-valued expressions A, B:</p>
<table align="center">
	<tr><th>Rationale</th><th></th><th>Name</th></tr>
	<tr><td align="center">P,Q &#9500; P</td><td align="left" valign="top" rowspan="2"></td></tr>
	<tr><td align="center">P,Q &#9500; Q</td></tr>
	<tr><td align="center" style="background: yellow">A, (A &#9500; B) &#9500; (A &#9500; B)</td><td style="background: yellow">Idempotence of hypotheses of &#9500; (example of schema)</td></tr>
</table>
<p>Of the above, only <i>idempotence of &</i> can be said to be formally derivable (by evaluating either of the uniform substitutions, named in the rationale).  The others are meaning-based, i.e. semantic, translations 
	between different descriptions of logical and &.</p>
<p>How we motivated <i>conjunction introduction</i>, is an example of the procedure of condensed detachment, developed by Carew Arthur Meredith in the 1950's.  We just used a different inference rule
	(a representation of the sole truth-table row for which logical and & evaluates to true), than the usual <i>modus ponens</i>.  We would expect</p>
	<p align="center">(<i>true</i> & <i>true</i> &#x21A6; <i>true</i>)[(Q, P, P & Q),(<i>true</i>, <i>true</i>, <i>true</i>)]</p>
<p>to be an equally "authorized" non-uniform substitution into the truth-table based inference rule.  The intended interpretation of &#9500; then gives <i>commutativity of &</i>.  The corresponding 
structural rule for &#9500;, is that the labeling order of statements used in a derivation rule doesn't matter.</p>
<p>The above, however, does not justify the substitution [Q & P/P & Q] by itself: we only verified that this is valid when <i>P</i> & <i>Q</i> evaluates to <i>true</i>.  To be confident
	that [Q & P/P & Q] is a valid substitution, we expect the values of <b>all</b> truth table rows to be unchanged by interchanging the columns labeled P and Q.
	We expect the equivalent symbolic notation, is that the order of using &#9500; and [Q & P/P & Q] does not matter.</p>
<ul>
	<li>Exercise: [Q & P/P & Q] is a valid substitution for five of the logics we are interested in.  This fails for Lisp/Prolog.</li>
	<li>Exercise: [Q &#x2228; P/P &#x2228; Q] is a valid substitution for five of the logics we are interested in.  This also fails for Lisp/Prolog.  
		We have an explicit counter-example for syntactical entailment for Lisp/Prolog logic: <i>true</i> &#x2228; <i>unknown</i> &#x21A6; <i>true</i>, but <i>unknown</i> &#x2228; <i>true</i> &#x21A6; <i>unknown</i>.
	</li>
</ul>
<table align="center">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P & Q &#x27DB; Q & P</td><td><span style="background:yellow">(syntactical)</span> Commutativity of &</td><td>None</td><td>None</td></tr>
	<tr><td align="center">A &#x27DB; A[Q & P/P & Q]</td><td>Commutativity of &</td><td>Lisp/Prolog</td><td>None</td></tr>
	<tr><td align="center">A &#x27DB; A[Q &#x2228; P/P &#x2228; Q]</td><td>Commutativity of &#x2228;</td><td>Lisp/Prolog</td><td>None</td></tr>
</table>

<table align="left">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>(P & Q) & R</td><td>Given</td></tr>
	<tr><td>2.</td><td>P & Q</td><td>Conjunction elimination on (1)</td></tr>
	<tr><td>3.</td><td>R</td><td>Conjunction elimination on (1)</td></tr>
	<tr><td>4.</td><td>P</td><td>Conjunction elimination on (2)</td></tr>
	<tr><td>5.</td><td>Q</td><td>Conjunction elimination on (2)</td></tr>
	<tr><td>6.</td><td>Q & R</td><td>Conjunction introduction on (5),(3)</td></tr>
	<tr><td>7.</td><td>P & (Q & R)</td><td>Conjunction introduction on (4),(6)</td></tr>
</table>
<table align="right">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P & (Q & R)</td><td>Given</td></tr>
	<tr><td>2.</td><td>Q & R</td><td>Conjunction elimination on (1)</td></tr>
	<tr><td>3.</td><td>P</td><td>Conjunction elimination on (1)0</td></tr>
	<tr><td>4.</td><td>Q</td><td>Conjunction elimination on (2)</td></tr>
	<tr><td>5.</td><td>R</td><td>Conjunction elimination on (2)</td></tr>
	<tr><td>6.</td><td>P & Q</td><td>Conjunction introduction on (3),(4)</td></tr>
	<tr><td>7.</td><td>(P & Q) & R</td><td>Conjunction introduction on (6),(5)</td></tr>
</table>

<p>Here we use <i>conjunction introduction</i> and <i>conjunction elimination</i> to derive <i>associativity of &</i>.  We are arguably implicitly using
<i>commutativity of &</i> as well, to justify ignoring the relative order of preceding statements when using inference rules.</p>
<p>In general, an associativity principle allows notation to omit internal grouping parentheses. We now consider <i>P & Q & R</i> unambiguous as a top-level statement, 
	syntactically equivalent to both choices of parenthesization.</p>
<p>There is a corresponding principle of generalized associativity of &, but we do not yet have the formal notation to prove it. It is credible, that
	enough uses of conjunction elimination, followed by enough uses of conjunction introduction, would allow syntactical equivalence between any two fixed parenthesizations 
	of an arbitrary (finite) number of clauses.  Likewise, there is a corresponding rearrangement principle of & that requires both associativity of & and 
	commutativity of &, but we don't have the notation to prove that either.  I will use these principles in the reference tables supporting 
	this summary.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P & Q & R &#x27DB; (P & Q) & R &#x27DB; P & (Q & R)</td><td align="left" valign="top"><span style="background:yellow">(syntactical)</span> Associativity of &</td><td align="left" valign="top" rowspan="2">None</td><td align="left" valign="top" rowspan="2">None</td></tr>
</table>
<p>We next consider the truth-table description of logical not ~.  The inference rules corresponding to the tabular description (for those truth values that exist in a given logic) are:</p>
<p align="center">(P &#x21A6; <i>true</i>) &#9500; (~P &#x21A6; <i>false</i>)
	<br>(P &#x21A6; <i>false</i>) &#9500; (~P &#x21A6; <i>true</i>)
	<br>(P &#x21A6; <i>unknown</i>) &#9500; (~P &#x21A6; <i>unknown</i>)
	<br>(P &#x21A6; <i>contradiction</i>) &#9500; (~P &#x21A6; <i>contradiction</i>)</p>
<p>Since we only have one inference rule for each result, these are actually &#x27DB; rather than &#9500; .  (This part doesn't work for Intuitionistic logic -- 
	we're relying on truth-valued expressions always having truth values, which isn't valid for Intuitionistic logic.)  It is a mechanical exercise that if P evaluates to a given truth value,
	then ~~P evaluates to that same truth value.  In particular, we have:</p>
<table align="center">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">A &#9500; A[~~P/P]</td><td>Introduce double negation</td><td>None</td><td>None</td></tr>
	<tr><td align="center">A &#9500; A[P/~~P]</td><td>Remove double negation</td><td>None</td><td><a href="https://plato.stanford.edu/entries/disjunction/">Intuitionistic</a></td></tr>
	<tr><td align="center">P &#9500; ~~P</td><td>Introduce double negation</td><td>None</td><td>None</td></tr>
	<tr><td align="center">~~P &#9500; P</td><td>Remove double negation</td><td>None</td><td><a href="https://plato.stanford.edu/entries/disjunction/">Intuitionistic</a></td></tr>
</table>
<p>Non-uniform substitutions are also allowed.  The third and fourth rows are for emphasis; they are special cases of the first two rows.</p>
<table align="right">
	<tr><th colspan="4">Classical Logic</th></tr>
	<tr><th></th><th>Inference rule</th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td></td><td>(A &#x21A6; <i>false</i>) &#x2228; (A &#x21A6; <i>true</i>)</td><td>Principle of bivalence</td></tr>
	<tr><td>2.</td><td></td><td>~~(A &#x21A6; <i>false</i>) &#x2228; (A &#x21A6; <i>true</i>)</td><td>Introduce double negation on (1)</td></tr>
	<tr><td>3.</td><td></td><td>~(A &#x21A6; <i>false</i>) &rArr; (A &#x21A6; <i>true</i>)</td><td>Definition of &rArr; on (2)</td></tr>
	<tr><td>4.</td><td>~(A &#x21A6; <i>false</i>) &#9500; (A &#x21A6; <i>true</i>)</td><td></td><td><span style="background:yellow">Upgrade &rArr; to &#9500;</span> on (3)</td></tr>
	<tr><td>5.</td><td>(A &#x21A6; <i>true</i>) &#x27DB; ~(A &#x21A6; <i>false</i>)</td><td></td><td>Defintion of &#x27DB; on law of non-contradiction, (4)</td></tr>
	<tr><td>6.</td><td></td><td>(A &#x21A6; <i>true</i>) &#x2228; (A &#x21A6; <i>false</i>)</td><td>Commutativity of &#x2228; on (1)</td></tr>
	<tr><td>7.</td><td></td><td>~~(A &#x21A6; <i>true</i>) &#x2228; (A &#x21A6; <i>false</i>)</td><td>Introduce double negation on (6)</td></tr>
	<tr><td>8.</td><td></td><td>~(A &#x21A6; <i>true</i>) &rArr; (A &#x21A6; <i>false</i>)</td><td>Definition of &rArr; on (7)</td></tr>
	<tr><td>9.</td><td>~(A &#x21A6; <i>true</i>) &#9500; (A &#x21A6; <i>false</i>)</td><td></td><td><span style="background:yellow">Upgrade &rArr; to &#9500;</span> on (8)</td></tr>
	<tr><td>10.</td><td>(A &#x21A6; <i>false</i>) &#x27DB; ~(A &#x21A6; <i>true</i>)</td><td></td><td>Defintion of &#x27DB; on law of non-contradiction, (9)</td></tr>
</table>
<p>For classical logic only, this allows upgrading the principle of non-contradiction to a syntactical equivalence, from a syntactical entailment.  This in 
	turn enables <b>any</b> syntactical equivalence &#x27DB; to justify the corresponding substitutions, for classical logic only.</p>

<p>All six of our logics, agree that the only truth table row for which <i>P & P</i> evaluates to <i>true</i> is <i>true</i> & <i>true</i> &#x21A6; <i>true</i>.  Likewise, they agree that the only truth table row for 
	which <i>P &#x2228; P</i> evaluates to <i>true</i>, is <i>true</i> &#x2228; <i>true</i> &#x21A6; <i>true</i>.  Furthermore, this is also the case for the other relevant truth values of <i>false</i>, <i>unknown</i>, <i>contradiction</i>: we have valid 
	substitutions [P & P/P], [P/P & P], [P &#x2228; P/P], [P/P &#x2228; P]. Translating this gives us the idempotence inference rules for  logical and &, and logical or &#x2228;. (We already had seen <i>idempotence of &</i>; this is a distinct motivation.)</p>
<p>These have corresponding structural rules for &#9500; .</p>
<table align="center">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">A &#x27DB; A[P/P & P]</td><td>Idempotence of &</td><td>None</td><td>None</td></tr>
	<tr><td align="center">A &#x27DB; A[P/P &#x2228; P]</td><td>Idempotence of &#x2228;</td><td>None</td><td>None</td></tr>
	<tr><td align="center">P & P &#x27DB; P</td><td>Idempotence of &</td><td>None</td><td>None</td></tr>
	<tr><td align="center">P &#x2228; P &#x27DB; P</td><td>Idempotence of &#x2228;</td><td>None</td><td>None</td></tr>
</table>

<h2 id="constructive-dilemma" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Constructive Dilemma</h2>
<table align="right">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &rArr; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>R &rArr; S</td><td>Given</td></tr>
	<tr><td>3.</td><td>P &#x2228; R</td><td>Given</td></tr>	
	<tr><td>4.</td><td>P &#x2228; S</td><td style="background: yellow">Right half of constructive dilemma on (3),(2)</td></tr>
	<tr><td>5.</td><td>Q &#x2228; S</td><td style="background: yellow">Left half of constructive dilemma on (5),(1)</td></tr>
</table>
<table align="left">
	<tr><th colspan="3">Typical proof</th></tr>
	<tr><th></th><th>Inference rule</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>~P &#x2228; Q, Q &rArr; R &#9500; ~P &#x2228; R</td><td>Apply [~P &#x2228; Q/P &rArr; Q][~P &#x2228; R/P &rArr; R] to <i>transitivity of implication</i></td></tr>
	<tr><td>2.</td><td>~~P &#x2228; Q, Q &rArr; R &#9500; ~~P &#x2228; R</td><td>Apply [~P/P] to (1)</td></tr>
	<tr><td>3.</td><td>P &#x2228; Q, Q &rArr; R &#9500; P &#x2228; R</td><td>Remove double negation</td></tr>
	<tr><td>4.</td><td>P &#x2228; R, R &rArr; S &#9500; P &#x2228; S</td><td>Apply [R/Q,S/R] to (3)</td></tr>
	<th colspan="3" style="background:yellow">Right half of constructive dilemma</th>
	<tr><td>5.</td><td>Q &#x2228; P, Q &rArr; R &#9500; P &#x2228; R</td><td>Commutativity of &#x2228;</td></tr>
	<tr><td>6.</td><td>P &#x2228; R, P &rArr; Q &#9500; R &#x2228; Q</td><td>Apply [P/Q,R/P,Q/R] to (5)</td></tr>
	<th colspan="3" style="background:yellow">Left half of constructive dilemma</th>
</table>
<p>For propositional variables P, Q, R, S: <i>P &rArr; Q</i> and <i>R &rArr; S</i> do not share any variables in common.  One way to introduce relevance,
	i.e. shared propositional variables, is <i>P &#x2228; R</i>.  We would expect the following:</p>
<p align="center">P &rArr; Q, R &rArr; S, P &#x2228; R &#9500; Q &#x2228; S</p>
<p>One way to proceed, is to first prove a lemma for the right half.  It is simplest to start by transforming <i>transitivity of implication</i>.  The given proofs are for 
classical logic, since we have so far only derived <i>transitivity of implication</i> for classical logic.</p>
<p>The same steps work when transforming <i style="background:yellow">Using Q &#9500; R on the conclusion of P &rArr; Q</i>, as <i>transitivity of implication</i>.  This 
	gives three more inference rules.</p>
<p>We have a counterexample for Lisp/Prolog logic: if P is <i>false</i> while R and S are both <i>true</i>, the truth value imputed to Q is unconstrained.  This is 
	not a material issue for our other truth-table described logics, but for Lisp/Prolog assigning Q a truth value of <i>unknown</i> causes Q &#x2228; S to be 
	<i>unknown</i>.  Our givens only guarantee that P and R have classical truth values.</p>
<p>Once we have verified that truth table calculations and (classical) symbolic logic calculations are equivalent, the exercise that <i>constructive dilemma</i> holds for Belnap's four-valued logic is doable.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &rArr; Q, R &rArr; S, P &#x2228; R &#9500; Q &#x2228; S</td><td align="left" rowspan="4">Constructive dilemma</td><td align="left" rowspan="4">Lisp/Prolog</td><td rowspan="4">Defeasible logics; Intuitionistic?</td></tr>
	<tr><td align="center" style="background:yellow">P &rArr; Q, (R &#9500; S), P &#x2228; R &#9500; Q &#x2228; S</td></tr>
	<tr><td align="center" style="background:yellow">(P &#9500; Q), R &rArr; S, P &#x2228; R &#9500; Q &#x2228; S</td></tr>
	<tr><td align="center" style="background:yellow">(P &#9500; Q), (R &#9500; S), P &#x2228; R &#9500; Q &#x2228; S</td></tr>
</table>

<h2 id="absorption" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Absorption</h2>
<table align="left">
	<tr><th></th><th>Inference rule</th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td></td><td>P &rArr; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td></td><td>P</td><td>Hypothesis</td></tr>
	<tr><td>3.</td><td></td><td>Q</td><td><i>modus ponens</i> on (1), (2)</td></tr>
	<tr><td>4.</td><td></td><td>P & Q</td><td>Conjunction introduction on (2), (3)</td></tr>
	<tr><td>5.</td><td>P &#9500; (P & Q)</td><td></td><td>Syntactical entailment introduction on (2), (4)</td></tr>
	<tr><th colspan="4">Classical logic</th></tr>
	<tr><td>5a.</td><td></td><td>P &rArr; (P & Q)</td><td>Implication introduction on (2), (4)</td></tr>
</table>
<table align="right">
	<tr><th></th><th>Inference rule</th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td></td><td>P &rArr; (P & Q)</td><td>Given</td></tr>
	<tr><td>2.</td><td></td><td>P</td><td>Hypothesis</td></tr>
	<tr><td>3.</td><td></td><td>P & Q</td><td><i>modus ponens</i> on (1), (2)</td></tr>
	<tr><td>4.</td><td></td><td>Q</td><td>Conjunction elimination on (3)</td></tr>
	<tr><td>5.</td><td>P &#9500; Q</td><td></td><td>Syntactical entailment introduction on (2), (4)</td></tr>
	<tr><th colspan="4">Classical logic</th></tr>
	<tr><td>5.</td><td>P &rArr; Q</td><td>Implication introduction on (2), (4)</td></tr>
</table>
<p>This technical manuever, is the rationale for "updating which statements are known".  The inverse direction does not have even a terse technical name.</p>
<p>The failure for Belnap's four-valued logic, is a semantic consequence of <i>unknown &rArr; contradiction</i> and <i>contradiction &rArr; unknown</i>, both 
	evaluating to <i>true</i>.  The other four non-classical logics have truth-table calculations as classical logic proofs, for the version that fails Belnap's four-valued logic.</p>
<p>The forward direction is generally useful in machine proofs.  The inverse direction is useful for preparing statements for long-term memorization.</p>
<p>The direct use of <i>modus ponens</i>, means we have analogs for syntactical entailment rules.  One of the inverse rules, suppresses the axiomatic identity entailment rule.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center" style="background:yellow">(P &#9500; Q) &#9500; (P &#9500; P & Q)</td><td align="left">Absorption</td><td align="left">None</td><td>Defeasible logics</td></tr>
	<tr><td align="center" style="background:yellow">P &rArr; Q &#9500; (P &#9500; P & Q)</td><td align="left">Absorption</td><td align="left">None</td><td>Defeasible logics</td></tr>
	<tr><td align="center">P &rArr; Q &#9500; P &rArr; (P & Q)</td><td align="left">Absorption</td><td align="left">Belnap</td><td>Defeasible logics</td></tr>
	<tr><td align="center" style="background:yellow">(P &#9500; P & Q) &#9500; (P &#9500; Q)</td><td align="left" style="background:yellow">Suppress identity entailment</td><td align="left">None</td><td>Defeasible logics</td></tr>
	<tr><td align="center" style="background:yellow">P &rArr; (P & Q) &#9500; (P &#9500; Q)</td><td align="left"></td><td align="left">None</td><td>Defeasible logics</td></tr>
	<tr><td align="center">P &rArr; (P & Q) &#9500; P &rArr; Q</td><td align="left"></td><td align="left">Belnap</td><td>Defeasible logics</td></tr>
</table>

<h2 id="reductio-ad-absurdum" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Proof by contradiction</h2>
<p>Following <a href="https://archive.org/details/principiamathema01anwh/page/n125/mode/2up"><i>Principia Mathematica</i></a> (hardcopy page 104, Vol. I; *2&middot;01), we consider the following:</p>
<table align="center">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &rArr; ~P</td><td>Given</td></tr>
	<tr><td>2.</td><td>~P &#x2228; ~P</td><td>Definition of &rArr;</td></tr>
	<tr><td>3.</td><td>~P</td><td>Idempotence of &#x2228;</td></tr>
</table>
In classical logic, this is known as <i>proof by contradiction</i>; other names include the Latin <i>reductio ad absurdum</i>.
<table align="center">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &rArr; ~P &#9500; ~P</td><td align="left">proof by contradiction</td><td align="left">None</td><td>None</td></tr>
</table>
<p>That is: unlike labeling a never-true statement "Given" in our tabular notation, labeling a never <i>true</i> statement "Hypothesis" is 
	one way of finding out a statement evaluates to the truth value <i>false</i>.  As mentioned earlier, the assumed statement must not have a non-classical truth value.</p>
<p>The corresponding syntactical inference rule, <i>P</i> &#9500; <i>~P</i> is proscribed by the <i>Principle of noncontradiction</i>.</p>
<h2 id="or-elimination" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Or elimination</h2>
<table align="left">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &#x2228; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>~P</td><td>Given</td></tr>
	<tr><td>3.</td><td>~~P &#x2228; Q</td><td>[~~P/P] Introduce double negation on (1)</td></tr>
	<tr><td>4.</td><td>~P &rArr; Q</td><td>Definition of &rArr; on (3)</td></tr>
	<tr><td>5.</td><td>Q</td><td><i>modus ponens</i> on (4),(2)</td></tr>
</table>
<table align="right">
	<tr><th colspan="3">Typical proof</th></tr>
	<tr><th></th><th>Inference rule</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &#x2228; Q, ~P &#9500; Q</td><td><span style="background:yellow">(left)</span> Or elimination</td></td></tr>
	<tr><td>2.</td><td>Q &#x2228; P, ~Q &#9500; P</td><td>apply [Q/P,P/Q] to (1)</td></tr>
	<tr><td>3.</td><td>P &#x2228; Q, ~Q &#9500; P</td><td>Commutativity of &#x2228; on (2)</td></tr>
</table>
<p>This is also known as disjunctive syllogism, and sometimes abbreviated as &#x2228;E.</p>
<p>The third step on the right is not valid for Lisp/Prolog logic.  We'll return to this later.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &#x2228; Q, ~P, &#9500; Q</td><td align="left"><span style="background:yellow">(left)</span> Or elimination</td><td align="left">None</td><td>Intuitionistic</td></tr>
	<tr><td align="center">P &#x2228; Q, ~Q, &#9500; P</td><td align="left"><span style="background:yellow">(right)</span> Or elimination</td><td align="left">None; expect proof for Lisp/Prolog later</td><td>Intuitionistic</td></tr>
</table>	

<h2 id="contrapositive-1" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Contrapositive</h2>
<p><i>Principia Mathematica</i> also suggests considering the following (*2&middot;03):</p>
<table align="center">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &rArr; ~Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>~P &#x2228; ~Q</td><td>Definition of &rArr;</td></tr>
	<tr><td>3.</td><td>~Q &#x2228; ~P</td><td>Commutativity of &#x2228;</td></tr>
	<tr><td>4.</td><td>Q &rArr; ~P</td><td>Definition of &rArr;</td></tr>
</table>
<p>In classical logic: this is one, of four versions, of taking the contrapositive of a nonstrict implication.  Another version 
	is *2.16 in <i>Principia Mathematica</i>.</p>
<table align="center">
	<tr><td>1.</td><td>P &rArr; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>P &rArr; ~~Q</td><td style="background: yellow">Introduce double negation on the conclusion of (1)</td></tr>
	<tr><td>3.</td><td>~P &#x2228; ~~Q</td><td>Definition of &rArr;</td></tr>
	<tr><td>4.</td><td>~~Q &#x2228; ~P</td><td>Commutativity of &#x2228;</td></tr>
	<tr><td>5.</td><td>~Q &rArr; ~P</td><td>Definition of &rArr;</td></tr>
</table>
<table align="center">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &rArr; ~Q &#9500; Q &rArr; ~P</td><td align="left">taking contrapositive</td><td align="left">Lisp/Prolog</td><td>None</td></tr>
	<tr><td align="center">P &rArr; Q &#9500; ~Q &rArr; ~P</td><td align="left">taking contrapositive</td><td align="left">Lisp/Prolog</td><td>None</td></tr>
</table>
<table align="left">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>~P &rArr; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>~Q &rArr; ~~P</td><td>Take contrapositive</td></tr>
	<tr><td>3.</td><td>~Q &rArr; P</td><td style="background: yellow">Remove double negation from the conclusion of (2)</td></tr>
</table>
<table align="right">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>~P &rArr; ~Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>~~Q &rArr; ~~P</td><td>Take contrapositive</td></tr>
	<tr><td>3.</td><td>~~Q &rArr; P</td><td style="background: yellow">Remove double negation from the conclusion of (2)</td></tr>
	<tr><td>4.</td><td>Q &rArr; P</td><td style="background: yellow">Invert adding double negation to the hypothesis of (3)</td></tr>
</table>
<p>There are two other versions of taking the contrapositive.  They involve removing double negation, so do not work for Intuitionistic logic.  We will review how to 
	identify the extra hypotheses required for this to work for Lisp/Prolog logic.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">~P &rArr; Q &#9500; ~Q &rArr; P</td><td align="left">taking contrapositive</td><td align="left">Lisp/Prolog</td><td>None</td></tr>
	<tr><td align="center">~P &rArr; ~Q &#9500; Q &rArr; P</td><td align="left">taking contrapositive</td><td align="left">Lisp/Prolog</td><td>Intuitionistic</td></tr>
</table>
<table align="left">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &hArr; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>(P &rArr; Q) & (Q &rArr; P)</td><td>Definition of &hArr; on (1)</td></tr>
	<tr><td>3.</td><td>P &rArr; Q</td><td>Conjunction elimination on (2)</td></tr>
	<tr><td>4.</td><td>Q &rArr; P</td><td>Conjunction elimination on (2)</td></tr>
	<tr><td>5.</td><td>~Q &rArr; ~P</td><td>Take contrapositive of (3)</td></tr>
	<tr><td>6.</td><td>~P &rArr; ~Q</td><td>Take contrapositive of (4)</td></tr>
	<tr><td>7.</td><td>~P &hArr; ~Q</td><td>Definition of &hArr; on (6),(5)</td></tr>
</table>
<table align="right">
	<tr><th colspan="4">Classical logic</th></tr>
	<tr><th></th><th>Inference Rule</th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>A &#x27DB; B</td><td></td><td>Given</td></tr>
	<tr><td>2.</td><td></td><td>A &hArr; B</td><td>Downgrade &#x27DB; to &hArr; on (1)</td></tr>
	<tr><td>3.</td><td></td><td>~A &hArr; ~B</td><td>Apply negation to both sides of &hArr; on (2)</td></tr>
	<tr><td>4.</td><td>~A &#x27DB; ~B</td><td></td><td>Upgrade &hArr; to &#x27DB; on (3)</td></tr>
</table>
<p>The other direction, removing negation from both sides of &hArr;, or from both sides of &#x27DB;, is left as an exercise.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &hArr; Q &#9500; ~P &hArr; ~Q</td><td align="left"><span style="background:yellow">Apply ~ to both sides of &hArr;</span></td><td align="left">Lisp/Prolog</td><td>None</td></tr>
	<tr><td align="center">~P &hArr; ~Q &#9500; P &hArr; Q</td><td align="left"><span style="background:yellow">Remove ~ from both sides of &hArr;</span></td><td align="left">Lisp/Prolog</td><td>Intuitionistic</td></tr>
</table>
<table align="center" style="clear:both">
	<tr><th colspan="2">Classical logic</th></tr>
	<tr><th></th><th>Name</th></tr>
	<tr><td align="center">(A &#x27DB; B) &#9500; (~A &#x27DB; ~B)</td><td align="left"><span style="background:yellow">Apply ~ to both sides of &#x27DB;</span></td></tr>
	<tr><td align="center">(~A &#x27DB; ~B) &#9500; (A &#x27DB; B)</td><td align="left"><span style="background:yellow">Remove ~ from both sides of &#x27DB;</span></td></tr>
</table>

<h2 id="modus-tollens" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px"><i>Modus Tollens</i></h2>
<table align="right">
	<tr><th colspan=3>Logics other than Lisp/Prolog</th></tr>
	<tr><td>1.</td><td>P &rArr; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>~Q</td><td>Given</td></tr>
	<tr><td>3.</td><td>~Q &rArr; ~P</td><td>Taking contrapositive of (1)</td></tr>
	<tr><td>4.</td><td>~P</td><td><i>modus ponens</i> on (3), (2)</td></tr>
</table>
<p>It would make sense that it should be possible to run <i>modus ponens</i> in reverse, when the negation <i>~Q</i> of the conclusion of <i>P &rArr; Q</i> is known.</p>
<p>This is known as (Latin) <i>modus tollens</i>, or "denying the consequent"; abbreviation MT.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &rArr; Q, ~Q &#9500; ~P</td><td align="left"><i>modus tollens</i></td><td align="left">None; expect to repair proof for Lisp/Prolog</td><td>None</td></tr>
</table>

<h2 id="modus-tollens-syntactical-entailment" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px"><i>modus tollens</i> for &#9500;</h2>
<table align="right">
<tr><th></th><th>Inference Rule</th><th>Proposition</th><th>Rationale</th></tr>
<tr><td>1.</td><td>A &#9500; B</td><td></td><td>Given</td></tr>
<tr><td>2.</td><td></td><td>~B</td><td>Given</td></tr>
<tr><td>3.</td><td></td><td>(A &#x21A6; <i>true</i>) &rArr; (B &#x21A6; <i>true</i>)</td><td><span style="background:yellow">Intended interpretation of &#x21A6;</span> (classical logic)</td></tr>
<tr><td>4.</td><td></td><td>B &#x21A6; <i>false</i></td><td><span style="background:yellow">Intended interpretation of &#x21A6;</span></td></tr>
<tr><td>5.</td><td></td><td>~(B &#x21A6; <i>true</i>)</td><td>Principle of non-contradiction (use conjunction elimination as needed)</td></tr>
<tr><td>6.</td><td></td><td>~(A &#x21A6; <i>true</i>)</td><td><i>modus tollens</i> on (3),(5)</td></tr>
<tr><th colspan="4">Classical Logic:</th></tr>
<tr><td>9.</td><td></td><td>~A</td><td><span style="background:yellow">Equivalence of ~A, and not evaluating to <i>true</i></span></td></tr>
</table>
<table align="left">
	<tr><th colspan="4">Classical Logic</th></tr>
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>~(A &#x21A6; <i>true</i>)</td><td>Given</td></tr>
	<tr><td>2.</td><td>(A &#x21A6; <i>true</i>) &#x2228; (A &#x21A6; <i>false</i>)</td><td>Principle of bivalence</td></tr>
	<tr><td>3.</td><td>A &#x21A6; <i>false</i></td><td>Or elimination on (7),(6)</td></tr>
	<tr><td>4.</td><td>~A</td><td><span style="background:yellow">Intended interpretation of &#x21A6;</span></td></tr>
	<tr><th colspan="4">~(A &#x21A6; <i>true</i>) &#9500; ~A</th></tr>
</table>
	
<p>This is more effective for classical logic, than the non-classical logics we are considering. We have one of these for each not-<i>true</i> truth value in 
	the logic the inference rule came from.  On the right, it looks like the steps labeled (2) and (4), are mainly to reach (5).  That is, we could have taken (5) as Given in 
	the general case.</p>
<p>The proof on the left, has a structurally similar version for <nobr>~(<i>A</i> &#x21A6; <i>false</i>).</nobr>  The other direction, is from the <i>principle of non-contradiction</i>. </p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Works for which of our logics?</th></tr>
	<tr><td align="center">A &#9500; B, ~B &#9500; ~(A &#x21A6; <i>true</i>)</td><td align="left"><i>modus tollens</i> for &#9500;</td><td align="left">Technically all</td></tr>
	<tr><td align="center">A &#9500; B, ~(B &#x21A6; <i>true</i>) &#9500; ~(A &#x21A6; <i>true</i>)</td><td align="left"><i>modus tollens</i> for &#9500;</td><td align="left">Technically all</td></tr>
	<tr><td align="center">A &#9500; B, ~B &#9500; ~A</td><td align="left"><i>modus tollens</i> for &#9500;</td><td align="left">Classical</td></tr>
	<tr><td align="center">~(A &#x21A6; <i>true</i>) &#x27DB; ~A</td><td align="left"><span style="background:yellow">Equivalence of ~A, and A not evaluating to <i>true</i></span></td><td align="left">Classical</td></tr>
	<tr><td align="center">~(A &#x21A6; <i>false</i>) &#x27DB; A</td><td align="left"><span style="background:yellow">Equivalence of A, and A not evaluating to <i>false</i></span></td><td align="left">Classical</td></tr>
</table>

<h2 id="destructive-dilemma" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Destructive Dilemma</h2>
<table align="left">
	<tr><th colspan="3">Logics other than Lisp/Prolog</th></tr>
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &rArr; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>R &rArr; S</td><td>Given</td></tr>
	<tr><td>3.</td><td>~Q &#x2228; ~S</td><td>Given</td></tr>	
	<tr><td>4.</td><td>~Q &rArr; ~P</td><td>Take contrapositive of (1)</td></tr>
	<tr><td>5.</td><td>~S &rArr; ~R</td><td>Take contrapositive of (2)</td></tr>
	<tr><td>6.</td><td>~P &#x2228; ~R</td><td>Constructive dilemma on (4),(5),(3)</td></tr>
</table>
<p>By analogy with <i>constructive dilemma</i> and <i>modus tollens</i>,  we would expect the following:</p>
<p align="center">P &rArr; Q, R &rArr; S, ~Q &#x2228; ~S &#9500; ~P &#x2228; ~R</p>
<p>Lisp/Prolog logic has a comparable counter-example, to its counter-example for <i>constructive dilemma</i>.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &rArr; Q, R &rArr; S, ~Q &#x2228; ~S &#9500; ~P &#x2228; ~R</td><td align="left">Destructive dilemma</td><td align="left">Lisp/Prolog</td><td>Defeasible logics; Intuitionistic?</td></tr>
</table>

<h2 id="classical-law-of-contradiction" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Classical Law of Contradiction</h2>
<table align="right">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &rArr; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>P &rArr; ~Q</td><td>Given</td></tr>
	<tr><td>3.</td><td>P</td><td>Hypothesis (for implication introduction)</td></tr>
	<tr><td>4.</td><td>~Q</td><td><i>modus ponens</i> on (2),(3)</td></tr>
	<tr><td>5.</td><td>~P</td><td><i>modus tollens</i> on (1),(4)</td></tr>
	<tr><td>6.</td><td>P &rArr; ~P</td><td>Implication introduction on (3), (5)</td></tr>
	<tr><td>7.</td><td>~P</td><td>Proof by contradiction [on (6)]</td></tr>
</table>
<p>This way of introducing relevance between two nonstrict implications, is known as the classical law of contradiction.  The given proof is for classical logic, due to the use of <i>implication introduction</i>.</p>
<p>This does not work for Belnap's four-valued logic, as a semantic consequence of <i>unknown</i> &rArr; <i>contradiction</i> evaluating to <i>true</i>.  The other non-classical logics 
   will have classical logic proofs using the truth table formalism, as exercises once that is established.</p>
<p>Replacing one of givens with a corresponding syntactical inference rule, is a mechanical alteration.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &rArr; Q, P &rArr; ~Q &#9500; ~P</td><td align="left">Classical law of contradiction</td><td align="left">Belnap</td><td>Defeasible logics</td></tr>
	<tr><td align="center">(P &#9500; Q), P &rArr; ~Q &#9500; ~P</td><td align="left">Classical law of contradiction</td><td align="left">Belnap</td><td>Defeasible logics</td></tr>
	<tr><td align="center">P &rArr; Q, (P &#9500; ~Q) &#9500; ~P</td><td align="left">Classical law of contradiction</td><td align="left">Belnap</td><td>Defeasible logics</td></tr>
</table>
<!--
<h2 id="classical-law-of-contradiction-syntactical-entailment" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Classical Law of Contradiction for </h2>
<table align="right">
	<tr><th></th><th>Inference Rule</th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &#9500; Q</td><td></td><td>Given</td></tr>
	<tr><td>2.</td><td>P &#9500; ~Q</td><td></td><td>Given</td></tr>
	<tr><td>3.</td><td>P &#9500; Q &#x21A6; <i>true</i></td><td></td><td><span style="background:yellow">Intended interpretation of &#x21A6;</span> on (1)</td></tr>
	<tr><td>4.</td><td>P &#9500; Q &#x21A6; <i>false</i></td><td></td><td><span style="background:yellow">Intended interpretation of &#x21A6;</span> on (2)</td></tr>
	<tr><td>5.</td><td>Q &#x21A6; <i>true</i> &#9500; ~(Q &#x21A6; <i>false</i>)</td><td></td><td>Principle of non-contradiction (use conjunction elimination as needed)</td></tr>
	<tr><td>6.</td><td>P &#9500; ~(Q &#x21A6; <i>false</i>)</td><td></td><td>cut rule, (3),(5)</td></tr>
	<tr><td>7.</td><td></td><td>(P &#x21A6; <i>true</i>) &rArr; ((Q &#x21A6; <i>false</i>) &#x21A6; <i>true</i>)</td><td><span style="background:yellow">Intended interpretation of &#x21A6;</span> on (4) [classical logic]</td></tr>
	<tr><td>8.</td><td></td><td>(P &#x21A6; <i>true</i>) &rArr; (~(Q &#x21A6; <i>false</i>) &#x21A6; <i>true</i>)</td><td><span style="background:yellow">Intended interpretation of &#x21A6;</span> on (6) [classical logic]</td></tr>
	<tr><td>9.</td><td></td><td>(P &#x21A6; <i>true</i>) &rArr; (Q &#x21A6; <i>false</i>)</td><td>Use <span style="background:yellow">Intended interpretation of &#x21A6;</span> on the consequence of (7) [classical logic]</td></tr>
	<tr><td>10.</td><td></td><td>(P &#x21A6; <i>true</i>) &rArr; ~(Q &#x21A6; <i>false</i>)</td><td>Use <span style="background:yellow">Intended interpretation of &#x21A6;</span> on the consequence of (8) [classical logic]</td></tr>
	<tr><td>11.</td><td></td><td>~(P &#x21A6; <i>true</i>)</td><td>Classical Law of contradiction on (9),(10) [back to using our target logic]</td></tr>
	<tr><td>12.</td><td>&#9500; ~(P &#x21A6; <i>true</i>)</td><td></td><td>Classical Law of contradiction on (9),(10) [back to using our target logic]</td></tr>
	<tr><th>Classical Logic</th></tr>
	<tr><td>13.</td><td>&#9500; ~P</td><td></td><td><span style="background:yellow">Equivalence of ~A, and A not evaluating to <i>true</i></span></td></tr>
</table>
<p>This is the strict parallel to the <i>classical law of contradiction</i>.  We have one of these, starting at steps (3) and (4) as givens, for each unordered pair of truth values in the target logic.</p>
-->

<h2 id="exportation" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px; clear:both">Exportation</h2>
<table align="left">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>(P & Q) &rArr; R</td><td>Given</td></tr>
	<tr><td>2.</td><td>P</td><td>Hypothesis (for implication introduction)</td></tr>
	<tr><td>3.</td><td>Q</td><td>Hypothesis (for implication introduction)</td></tr>
	<tr><td>4.</td><td>P & Q</td><td>Conjunction introduction on (2),</td></tr>
	<tr><td>5.</td><td>R</td><td><i>modus ponens</i> on (1), (4)</td></tr>
	<tr><td>6.</td><td>Q &rArr; R</td><td>Implication introduction on (3), (5)</td></tr>
	<tr><td>7.</td><td>P &rArr; (Q &rArr; R)</td><td>Implication introduction on (2), (6)</td></tr>
</table>
<table align="right">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &rArr; (Q &rArr; R)</td><td>Given</td></tr>
	<tr><td>2.</td><td>P & Q</td><td>Hypothesis (for implication introduction)</td></tr>
	<tr><td>3.</td><td>P</td><td>Conjunction elimination on (2)</td></tr>
	<tr><td>4.</td><td>Q &rArr; R</td><td><i>modus ponens</i> on (1), (3)</td></tr>
	<tr><td>5.</td><td>Q</td><td>Conjunction elimination on (2)</td></tr>
	<tr><td>6.</td><td>R</td><td><i>modus ponens</i> on (4), (5)</td></tr>
	<tr><td>7.</td><td>(P & Q) &rArr; R</td><td>Implication introduction on (2),(6)</td></tr>
</table>
<p>This is a sort of a packing/unpacking operation for nonstrict implication.  The "imported syntax" (using logical and & in the hypothesis) is the usual format for long-term 
	learning, while the "exported" syntax (using nonstrict implication &rArr; in the consequence) is more likely to be immediately usable.</p>
<p>These proofs are for classical logic.  All five non-classical logics we are considering, will have truth table calculations for this.</p>
<table align="center" style="clear:both">
	<tr><th colspan="4">Proven for: Classical logic</th></tr>
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">(P & Q) &rArr; R &#9500; P &rArr; (Q &rArr; R)</td><td align="left">Exportation from & to &rArr;</td><td align="left">None</td><td>Defeasible logics</td></tr>
	<tr><td align="center">P &rArr; (Q &rArr; R) &#9500; (P & Q) &rArr; R</td><td align="left">Importation from &rArr; to &</td><td align="left">None</td><td>Defeasible logics</td></tr>
	<tr><td align="center">(P & Q) &rArr; R &#x27DB; P &rArr; (Q &rArr; R)</td><td align="left" style="background:yellow">equivalence of exportation and importation</td><td align="left">None</td><td>Defeasible logics</td></tr>
</table>

<h2 id="de-morgan" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">De Morgan's Laws</h2>
<p>One of the truth table rows for logical or &#x2228; , translates to <i>false</i> &#x2228; <i>false</i> &#x21A6; <i>false</i>.  A corresponding Gentzen-style notation is</p>
<p align=center>(P &#x21A6; <i>false</i>) & (Q &#x21A6; <i>false</i>) &#9500; (P &#x2228; Q &#x21A6; <i>false</i>)</p>
<p>which, according our extended notation, rewrites to one of De Morgan's Laws.</p>
<table align="center">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">~P & ~Q &#9500; ~(P &#x2228; Q)</td><td align="left">De Morgan's Law <span style="background: yellow">-- wrap to not-or</span></td><td align="left">None</td><td valign="top" rowspan="3">None</td></tr>
	<tr><td align="center">~(P &#x2228; Q) &#9500; ~P & ~Q</td><td align="left">De Morgan's Law <span style="background: yellow">-- unwrap from not-or</span></td><td align="left">Franci</td></tr>
	<tr><td align="center">~(P &#x2228; Q) &#x27DB; ~P & ~Q</td><td align="left">De Morgan's Law</td><td align="left">Franci</td></tr>
</table>
<p>Franci fails the "unwrap from not or" half because, unlike the major truth-functional logics, she thinks <i>false</i> &#x2228; <i>contradiction</i> &#x21A6; <i>false</i>.  (The other logic with 
<i>contradiction</i>, Belnap's four-valued logic, has <i>false</i> &#x2228; <i>contradiction</i> &#x21A6; <i>contradiction</i>; thus, like the others, it has only <b>one</b> truth table row for logical or &#x2228; that evaluates to <i>false</i>.</p>
<table align="left">
	<tr><th></th><th>Inference rule</th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td></td><td>~P &#x2228; ~Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>~~P & ~~Q &#9500; ~(~P &#x2228; ~Q)</td><td></td><td>Apply [~P/P,~Q/Q] to De Morgan's Law <span style="background: yellow">-- wrap to not-or</span></td></tr>
	<tr><td>3.</td><td>P & Q &#9500; ~(~P &#x2228; ~Q)</td><td></td><td>Remove double negation</td></tr>
	<tr><td>4.</td><td></td><td>~(P & Q &#x21A6; <i>true</i>)</td><td><i>modus tollens</i> for &#9500;</td></tr>
	<tr><th colspan="4">Classical logic</th></tr>
	<tr><td>5.</td><td></td><td>~(P & Q)</td><td><span style="background:yellow">Equivalence of ~A, and A not evaluating to <i>true</i></span></td></tr>
</table>
<table align="right">
	<tr><th colspan="4">Logics other than Franci</th></tr>
	<tr><th></th><th>Inference rule</th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td></td><td>~(P & Q)</td><td>Given</td></tr>
	<tr><td>2.</td><td>~(~P &#x2228; ~Q) &#9500; ~~P & ~~Q</td><td></td><td>Apply [~P/P,~Q/Q] to De Morgan's Law <span style="background: yellow">-- unwrap from not-or</span></td></tr>
	<tr><td>3.</td><td>~(~P &#x2228; ~Q) &#9500; P & Q</td><td></td><td>Remove double negation</td></tr>
	<tr><td>4.</td><td></td><td>~(~(~P &#x2228; ~Q) &#x21A6; <i>true</i>)</td><td><i>modus tollens</i> for &#9500;</td></tr>
	<tr><th colspan="4">Classical logic</th></tr>
	<tr><td>5.</td><td></td><td>~~(~P &#x2228; ~Q)</td><td><span style="background:yellow">Equivalence of ~A, and A not evaluating to <i>true</i></span></td></tr>
	<tr><td>6.</td><td></td><td>~P &#x2228; ~Q</td><td>Remove double negation</td></tr>
</table>
<p>The given proofs are for classical logic.  We'll return to these, once we can translate truth table descriptions to symbolic logic.  The usages of "<i>modus tollens</i> for &#9500;" can be replaced by
	implication introduction, for classical logic.  This choice of format, prepares a common core for the non-classical logic proofs.</p>
<p>Generally, working with truth table-formatted calculations involving multiple rows,
	relies heavily on both associativity and distributivity rules for logical and & and logical or &#x2228; .  We'll need the distributivity laws, to get 
	alternate proofs for the nonclassical logics.</p>
<p>The intended interpretation of Intuitionistic logic, suggests that <i>~(P & Q) &#9500; ~P &#x2228; ~Q</i> should be invalid: a direct proof of 
	~(P & Q), would not be expected to give a proof of either ~P or ~Q.  One of our authoritative sources (Stanford Encylopedia of Philosophy) confirms both this, and that 
	the other three syntactical entailments do work for Intuitionistic logic.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">~P &#x2228; ~Q &#9500; ~(P & Q)</td><td align="left">De Morgan's Law <span style="background: yellow">-- wrap to not-and</span></td><td align="left">Franci</td><td>None</td></tr>
	<tr><td align="center">~(P & Q) &#9500; ~P &#x2228; ~Q</td><td align="left">De Morgan's Law <span style="background: yellow">-- unwrap from not-and</span></td><td align="left">None</td><td>Intuitionistic</td></tr>
</table>
	
<h2 id="associativity-or" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Associativity of &#x2228;</h2>
<table align="right">
	<tr><th colspan="3">Classical logic</th></tr>
	<tr><th></th><th>Inference Rule</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>~(P & Q) &#x2228; R &#x27DB; ~P &#x2228; (Q &rArr; R)</td><td>Definition of &rArr; on equivalence of exportation and importation</td></tr>
	<tr><td>2.</td><td>~(P & Q) &#x2228; R &#x27DB; ~P &#x2228; (~Q &#x2228; R)</td><td>Definition of &rArr; on (1)</td></tr>
	<tr><td>3.</td><td>(~P &#x2228; ~Q) &#x2228; R &#x27DB; ~P &#x2228; (~Q &#x2228; R)</td><td>De Morgan's Law on (2) [substitution rather than syntactical equivalence]</td></tr>
	<tr><td>4.</td><td>(~~P &#x2228; ~~Q) &#x2228; R &#x27DB; ~~P &#x2228; (~~Q &#x2228; R)</td><td>Apply [~P/P, ~Q/Q] to (3)</td></tr>
	<tr><td>5.</td><td>(P &#x2228; Q) &#x2228; R &#x27DB; P &#x2228; (Q &#x2228; R)</td><td>Remove double negation</td></tr>
</table>
<p>We'll return to this later, for the non-classical logics.  As with logical and &, when we have <i>associativity of</i> &#x2228; we consider 
	<nobr><i>P &#x2228; Q &#x2228; R</i></nobr> unambiguous, syntactically equivalent to both sides of <i>associativity of</i> &#x2228;.</p>
<p>Like logical and &, we have principles of generalized associativity of &#x2228;, and rearrangement of &#x2228;.  As before, we do 
	not yet have the notation to prove them.</p>
<table align="center" style="clear:both">
	<tr><th colspan="4">Proven for: Classical logic</th></tr>
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &#x2228; Q &#x2228; R &#x27DB; P &#x2228; (Q &#x2228; R) &#x27DB; (P &#x2228; Q) &#x2228; R</td><td align="left">Associativity of &#x2228;</td><td align="left">None</td><td>None</td></tr>
</table>

<h2 id="modus-ponendo-tollens" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px"><i>modus ponendo tollens</i></h2>
<table align="left">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>~(P & Q)</td><td>Given</td></tr>
	<tr><td>2.</td><td>P</td><td>Given</td></tr>
	<tr><td>3.</td><td>~P &#x2228; ~Q</td><td>De Morgan's Law <span style="background:yellow">-- unwrap from not-and</span> on (1)</td></tr>
	<tr><td>4.</td><td>P &rArr; ~Q</td><td>Definition of &rArr;</td></tr>
	<tr><td>5.</td><td>~Q</td><td><i>modus ponens</i> on (4),(2)</td></tr>
</table>	
<table align="right">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>~(P & Q)</td><td>Given</td></tr>
	<tr><td>2.</td><td>Q</td><td>Given</td></tr>
	<tr><td>3.</td><td>~P &#x2228; ~Q</td><td>De Morgan's Law <span style="background:yellow">-- unwrap from not-and</span> on (1)</td></tr>
	<tr><td>4.</td><td>P &rArr; ~Q</td><td>Definition of &rArr;</td></tr>
	<tr><td>5.</td><td>~~Q</td><td>introduce double negation on (2)</td></tr>
	<tr><td>6.</td><td>~P</td><td><i>modus tollens</i> on (4),(5)</td></tr>
</table>
<p>Latin for "mode that denies by affirming".</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">~(P & Q), P &#9500; ~Q</td><td align="left" rowspan="2"><i>modus ponendo tollens</i></td><td align="left">None</td><td>Intuitionistic</td></tr>
	<tr><td align="center">~(P & Q), Q &#9500; ~P</td><td align="left">None</td><td>Intuitionistic</td></tr>
</table>

<h2 id="distribuvity-or-and" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px; clear:both">Distributivity of &#x2228; with respect to &</h2>
<table align="left">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &#x2228; (Q & R)</td><td>Given</td></tr>
	<tr><td>2.</td><td>~~P &#x2228; (Q & R)</td><td>Introduce double negation on (2)</td></tr>
	<tr><td>3.</td><td>~P &rArr; (Q & R)</td><td>Definition of &rArr;</td></tr>
	<tr><td>4.</td><td>~P &rArr; Q</td><td style="background:yellow">Use conjunction elimination on the consequence of (3)</td></tr>
	<tr><td>5.</td><td>~P &rArr; R</td><td style="background:yellow">Use conjunction elimination on the consequence of (3)</td></tr>
	<tr><td>6.</td><td>~~P &#x2228; Q</td><td>Definition of &rArr; on (4)</td></tr>
	<tr><td>7.</td><td>~~P &#x2228; R</td><td>Definition of &rArr; on (5)</td></tr>
	<tr><td>8.</td><td>(~~P &#x2228; Q) & (~~P &#x2228; R)</td><td>Conjunction introduction on (6),(7)</td></tr>
	<tr><td>9.</td><td>(P &#x2228; Q) & (P &#x2228; R)</td><td>Remove double negation on (8)</td></tr>
</table>
<table align="right">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>(P &#x2228; Q) & (P &#x2228; R)</td><td>Given</td></tr>
	<tr><td>2.</td><td>(~~P &#x2228; Q) & (~~P &#x2228; R)</td><td>Introduce double negation on (2)</td></tr>
	<tr><td>3.</td><td>~~P &#x2228; Q</td><td>Conjunction elimination on (2)</td></tr>
	<tr><td>4.</td><td>~~P &#x2228; R</td><td>Conjunction elimination on (2)</td></tr>
	<tr><td>5.</td><td>~P &rArr; Q</td><td>Definition of &rArr; on (3)</td></tr>
	<tr><td>6.</td><td>~P &rArr; R</td><td>Definition of &rArr; on (4)</td></tr>
	<tr><td>7.</td><td>~P</td><td>Hypothesis</td></tr>
	<tr><td>8.</td><td>Q</td><td><i>modus ponens</i> on (5),(7)</td></tr>
	<tr><td>9.</td><td>R</td><td><i>modus ponens</i> on (6),(7)</td></tr>
	<tr><td>10.</td><td>Q & R</td><td>conjunction introduction on (8),(9)</td></tr>
	<tr><td>11.</td><td>~P &rArr; (Q & R)</td><td>Implication introduction on (7),(11)</td></tr>
	<tr><td>12.</td><td>~~P &#x2228; (Q & R)</td><td>Definition of &rArr; on (11)</td></tr>
	<tr><td>13.</td><td>P &#x2228; (Q & R)</td><td>Remove double negation on (12)</td></tr>
</table>
<p>The proof on the left works for all of the logics we are considering.  The proof on the right is for classical logic; as usual, the hypothesis step needs some assurance
	that P has a classical truth value, to be valid.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &#x2228; (Q & R) &#x27DB; (P &#x2228; Q) & (P &#x2228; R)</td><td align="left">Left distributivity of &#x2228; over &</td><td align="left">None</td><td>None</td></tr>
</table>
<table align="left">
	<tr><th colspan="3">Typical</th></tr>
	<tr><th></th><th>Inference rule</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &#x2228; (R & Q) &#x27DB; (P &#x2228; R) & (P &#x2228; Q)</td><td>Commutativity of & on Left distributivity of &#x2228; over &</td></tr>
	<tr><td>2.</td><td>(R & Q) &#x2228; P &#x27DB; (R &#x2228; P) & (Q &#x2228; P)</td><td>Commutativity of &#x2228; on (1)</td></tr>
</table>
<p>We will need a different technique for Lisp/Prolog logic.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">(Q & R) &#x2228; P &#x27DB; (Q &#x2228; P) & (R &#x2228; P)</td><td align="left">Right distributivity of &#x2228; over &</td><td align="left">None; expecting to prove for Lisp/Prolog</td><td>None</td></tr>
</table>

<table align="right">
	<tr><th colspan="3">Classical logic</th></tr>
	<tr><th></th><th>Inference rule</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>~(P &#x2228; (Q & R)) &#x27DB; ~((P &#x2228; Q) & (P &#x2228; R))</td><td style="background:yellow">Apply ~ to both sides of left distributivity of &#x2228; over &</td></tr>
	<tr><td>2.</td><td>~P & ~(Q & R) &#x27DB; ~((P &#x2228; Q) & (P &#x2228; R))</td><td>De Morgan's Law <span style="background:yellow">-- unwrap from not-or</span></td></tr>
	<tr><td>3.</td><td>~P & (~Q &#x2228; ~R) &#x27DB; ~(P &#x2228; Q) &#x2228; ~(P &#x2228; R)</td><td>De Morgan's Law <span style="background:yellow">-- unwrap from not-and</span></td></tr>
	<tr><td>4.</td><td>~P & (~Q &#x2228; ~R) &#x27DB; (~P & ~Q) &#x2228; (~P & ~R)</td><td>De Morgan's Law <span style="background:yellow">-- unwrap from not-or</span></td></tr>
	<tr><td>5.</td><td>~~P & (~~Q &#x2228; ~~R) &#x27DB; (~~P & ~~Q) &#x2228; (~~P & ~~R)</td><td>Apply [~P/P,~Q/Q,~R/R] to (4)</td></tr>
	<tr><td>6.</td><td>P & (Q &#x2228; R) &#x27DB; (P & Q) &#x2228; (P & R)</td><td>Remove double negation</td></tr>
	<tr><td>7.</td><td>(Q &#x2228; R) & P &#x27DB; (Q & P) &#x2228; (R & P)</td><td>Commutativity of &</td></tr>
</table>
<p>For classical logic, we can get left distributivity of & over &#x2228; with De Morgan's Law.  Right distributivity of & over &#x2228; then is an application of commutativity of &.  This critically 
	depends on classical logic's unique ability to use &#x27DB; to justify substitutions.</p>
<table align="center" style="clear:both">
	<tr><th colspan="4">Proven for: Classical logic</th></tr>
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P & (Q &#x2228; R) &#x27DB; (P & Q) &#x2228; (P & R)</td><td align="left">Left distributivity of & over &#x2228;</td><td align="left">None</td><td>None</td></tr>
	<tr><td align="center">(Q &#x2228; R) & P &#x27DB; (Q & P) &#x2228; (R & P)</td><td align="left">Right distributivity of & over &#x2228;</td><td align="left">None</td><td>None</td></tr>
</table>

<h2 id="proof-by-cases" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Proof by cases</h2>
<table align="left">
	<tr><th></th><th>Inference Rule</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &rArr; Q, R &rArr; Q, P &#x2228; R &#9500; Q &#x2228; Q</td><td>Apply [Q/S] to constructive dilemma</td></tr>
	<tr><td>2.</td><td>P &rArr; Q, R &rArr; Q, P &#x2228; R &#9500; Q</td><td>Transivity of syntactical entailment, (1) and idempotence of &#x2228;</td></tr>
</table>
<table align="right">
	<tr><th colspan="3">Typical</th></tr>
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &rArr; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>R &rArr; Q</td><td>Given</td></tr>
	<tr><td>3.</td><td>P &#x2228; R</td><td>Given</td></tr>
	<tr><td>4.</td><td>~P &#x2228; Q</td><td>Definition of &rArr; on (1)</td></tr>
	<tr><td>5.</td><td>~R &#x2228; Q</td><td>Definition of &rArr; on (2)</td></tr>
	<tr><td>6.</td><td>(~P &#x2228; Q) & (~R &#x2228; Q)</td><td>Conjunction introduction on (4),(5)</td></tr>
	<tr><td>7.</td><td>(~P & ~R) &#x2228; Q</td><td>Right distributivity of &#x2228; over &</td></tr>
	<tr><td>8.</td><td>~(~P & ~R) &rArr; Q</td><td>Definition of &rArr;</td></tr>
	<tr><td>9.</td><td>(~~P &#x2228; ~~R) &rArr; Q</td><td style="background:yellow">Inverting using De Morgan's Law -- wrap to not-and on hypothesis of (8)</td></tr>
	<tr><td>10.</td><td>(P &#x2228; R) &rArr; Q</td><td>Remove double negation</td></tr>
	<tr><td>11.</td><td>Q</td><td><i>modus ponens</i> on (10),(3)</td></tr>
</table>
<p>Two distinct proofs (the left one goes through <i>transitivity of implication</i>, the right one through <i>Right distributivity of &#x2228; over &</i>).  Currently for classical logic.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &rArr; Q, R &rArr; Q, P &#x2228; R  &#9500; Q</td><td align="left">Proof by cases</td><td align="left">None</td><td>Defeasible logics</td></tr>
</table>
<p>At this point, I considered introducing a proof of generalized associativity of &.  This did not work out, because we do not yet have a way of
	counting how many clauses are being subject to generalized associtivity.

<!--
<h2 align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px; background:orange">Generalized Associativity</h2>
<p>To simplify our notation, we would like to have a notion of generalized associativity for logical and & and logical or &#x2228;.  That is, we would like the exact 
	parenthesization to not matter for <i>A1</i> & <i>A2</i> & ... & <i>An</i> or <i>A1</i> &#x2228; <i>A2</i> &#x2228; ... &#x2228; <i>An</i>.</p>
<p>Traditionally, this is proven <b>after</b> we have natural numbers 0, 1, ... , using strong induction.  But for this exercise, we do not have, formally, 
	(a model of) natural numbers.  That is, we do not have the notation to count the number of clauses, so we cannot just describe the algorithm: 
	"use conjunction elimination n times, then use conjunction introduction n-1 times".</p>
<p>We say an inductive proof, i.e. proof by induction, is a proof whose formalism is a proof by cases, such that we have:</p>
<ul>
	<li>At least one basis step i.e. case B, that is either axiomatically or provably true.</li>
	<li>At least one induction step i.e. case Q, that is provably true from a premise P that is (usually constructively) nameable from the induction step itself.  We say that:
		<ul>
			<li>The statement to be proven by induction Q, is a successor statement of the premise P named from the induction step.  There may be many successor statements Q for 
				a specific premise P</li>
			<li>The premise P named from the induction step, is a predecessor statement of the statement to be proven by induction Q.  There can be only one predecessor statement 
				P for a given induction step Q.</li>
		</ul></li>
</ul>
<p>Taking statements to be first order, the predecessor statement and successor statement "relations" are similar to syntactical entailment &#9500; .  We thus expect these 
	proof-specific "relations" to be second order on the domain of discourse truth-valued expressions.  We consider the induction step Q proven for all instances that are 
	reachable from any of the basis steps B by repeatedly applying the proof-specific successor statement "relation".  When reasoning about inference rules (which are second 
	order on domain of discourse truth-valued expressions), these proof-specific "relations" are third order on domain of discourse truth-valued expressions.</p>
<p>The effect is to prove the induction step Q, for all instances that are reachable from the basis step(s) B, by repeated use of the successor statement "relation".  My intention is 
	that this improvised definition, has all of weak natural induction, strong natural induction, finite induction, and transfinite induction as specializations.  That is, 
	the intent is to allow proving a logical and & statement with potentially unbounded clauses(!).  This behavior is similar to the universal quantifier <span style="transform:rotate(180deg);display:inline-block">A</span>.</p>
<ul>
	<li>The intended interpretation of <b>TruthValued</b>, is the domain of discourse of all syntactically truth-valued expressions.  (Whether these actually <b>have</b> truth values, i.e. are statements, depends on the logic applied to them.)</li>
	<li>The intended interpretation of <b>TruthValues</b>, is the domain of discourse of all truth values for a given logic.</li>
	<li>To denotate that a term a or variable x is in a domain of discourse, we will abuse the to-be-described &#x2208; notation.  E.g., for a propositional variable P, 
		we have P &#x2208; <b>TruthValued</b> with intended interpretation
		"P is a truth-valued expression".  Likewise, we have <i>true</i> &#x2208; <b>TruthValues</b> for all of the logics we are considering.</li>
	<li>The axiomatic identity inference rule <i>A</i> &#9500; <i>A</i>, may be thought of as evaluating all statements <i>A</i> to themselves.  Since we have a structural rule 
		that de-duplicates the hypotheses of an inference rule, this never infers any new statements not already present.</li>
	<li>As an example of an inference rule that takes a single hypothesis, consider the syntactical equivalence <i>idempotence of &</i>, which summarizes a pair of inference rules.  In the reverse direction, 
		this takes an arbitrary statement P and infers P & P.  The forward direction is only applicable to statements interpretable as instances of P & P, and infers P.</li>
	<li>The notation <i>A</i> &#x21A6; <i>true</i>, etc., we introduced, can be thought of as stating that a statement A evaluates to the truth value <i>true</i>, etc.  That suggests &#x21A6; should 
		have a domain contained within the domain of discourse all truth valued expressions, and range truth values.  Technically, &#x21A6; is taking the logic as an 
		implicit parameter.  These are predicates on the domain of discourse of syntactically truth-valued expressions.</li>
</ul>
<p>In particular, it is tempting to abuse notation yet to be defined and say that:</p>
<ul>
	<li>For domains of discourse D,E we say f:D <span style="position:relative; top: -2px">&#x2192;</span> E has domain D and range E.  We say f has type D <span style="position:relative; top: -2px">&#x2192;</span> E.  
		If we have an explicit definition f(x) := y, we have f(x) &#x21A6; y with intended interpretation "f of x evaluates to y".  Alternately,
		we have x &#x21A6;<sub>f</sub> y with intended interpretation "f of x evaluates to y".</li>
	<li>The syntactical inference rules summarized by <i>idempotence of &</i> both have type <b>TruthValued</b> <span style="position:relative; top: -2px">&#x2192;</span> <b>TruthValued</b>.</li>
	<li>The notation <i>A</i> &#x21A6; <i>true</i>, etc., we introduced, has type <b>TruthValued</b> <span style="position:relative; top: -2px">&#x2192;</span> <b>TruthValues</b>.</li>
</ul>
<p>With this notational extension, we see that the procedure for naming the predecessor statement P of the induction step Q for 
	an induction proof, has type <b>TruthValued</b> <span style="position:relative; top: -2px">&#x2192;</span> <b>TruthValued</b> restricted to "when it works".</p>
<p>Now, we have presumed that all statements either are, or are not, interpretable as having a "top-level" logical connective such as logical not ~,
	logical and &, or logical or &#x2228;.  Our rationale for wanting a generalized associativity principle, is that uniform substitution
	into <i>associativity of &</i>, etc. can replace a propositional variable (say, Q) that does <b>not</b> have a top-level logical connective &, with 
	a formal statement S & T that <b>does</b> have a top-level logical connective &.</p>
<p>Let's see if we have what we need to prove syntactical generalized associativity of &.  [Uniform substitution generalized associativity will need more work, for the non-classical logics.]  Let Connective<sub>&</sub>:<b>TruthValued</b> <span style="position:relative; top: -2px">&#x2192;</span> <b>TruthValues</b> have 
intended interpretation "this statement has a top-level logical connective of &".  We expect that:</p>
<table align="center">
<tr><td>~Connective<sub>&</sub>(T) for all truth values T</td><td rowspan="4"><span style="background:yellow">intended interpretation of Connective<sub>&</sub></span></td></tr>
<tr><td>~Connective<sub>&</sub>(~P) for all truth-valued expressions P.  We have a similar schema for all predicates p, taking arguments from any domain of discourse.</td></tr>
<tr><td>Connective<sub>&</sub>(P & Q) for all truth-valued expressions P, Q</td></tr>
<tr><td>~Connective<sub>&</sub>(P &#x2228; Q) for all truth-valued expressions P, Q.  We have a similar schema for all binary logical connectives other than &.</td></tr>
</table>
<table align="right">
<tr><th colspan="3">Classical Logic</th></tr>
<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
<tr><td>1.</td><td>Connective<sub>&</sub>((P & Q) & R)</td><td><span style="background:yellow">intended interpretation of Connective<sub>&</sub></span></td></tr>
<tr><td>2.</td><td>Connective<sub>&</sub>(P & Q & R)</td><td>Associativity of & [uniform substitution]</td></tr>
</table>
<p>All of our expectations are unconditional, i.e. axiomatic.  The lack of expectation of a truth value for Connective<sub>&</sub>(P), where P is a 
	propositional variable, is intentional: what we actually want there, is the value after (uniform) substitution [.../P].</p>
<p><i>A priori</i>, the obvious ways to introduce the non-classical truth values <i>unknown</i> or <i>contradiction</i> are:</p>
<ul>
	<li>Be unable to translate a truth-valued expression into formal notation at all (which could happen with natural language sentences as 
		truth valued expressions).</li>
	<li>A self-referential truth-valued expression, such as the liar paradox sentence "This sentence is false."</li>
	<li>For an un-substituted propositional variable, Connective<sub>&</sub>(P) &#x21A6; <i>unknown</i> may be appropriate.  However, this is not a typical usage of 
		propositional variables.  We can consider this an example of "inability to translate".</li>
</ul>
<p>None of these should be a problem in practice.  The self-referential case can look at the logical connectives that wrap the self-references.
	Likewise, a truth-valued expression that cannot be translated into formal notation at all, would be expected to not be well-formed 
	in the first place.  That is, it is reasonable to treat Connective<sub>&</sub> as having range, classical logic truth values.</p>
<p>An axiomatic inference rule that gives us the desired intended interpretation is</p>
<table align="center">
	<tr><td>Connective<sub>&</sub>(P) := (<span style="transform:rotate(180deg);display:inline-block">E</span>Q &#x2208; <b>TruthValued</b>)(<span style="transform:rotate(180deg);display:inline-block">E</span>R &#x2208; <b>TruthValued</b>)([Q & R/P] is a valid (uniform) substitution)</td><td rowspan="5"><span style="background:yellow">intended interpretation of Connective<sub>&</sub></span></td></tr>
</table>		
<p>Analogous definitions are adequate to define a predicate on <b>TruthValued</b>, that detects whether the top-most logical connective is logical not ~, or
	any other unary logical connective or unary predicate.  Binary logical connectives, such as logical and &, need more work.</p>
<p>Next, we would like a system of predicates on the domain of discourse of truth-valued expressions, that can be interpreted as "parsing" statements for logical and &.   In particular, we would like the left-most and right-most clauses 
	i.e. sub-statements P and R of a statement Q whose top-most logical connective is &, such 
	that P and R do not have a top-most logical connective of &.  Let Left<sub>&</sub> and Right<sub>&</sub> be of type <b>TruthValued</b> <span style="position:relative; top: -2px">&#x2192;</span> <b>TruthValued</b>.  We define:</p>
<table align="center">
	<tr><td align="right">Left<sub>&</sub>(P & Q)&nbsp;</td><td>:= P for all statements P, Q</td><td rowspan="3"><span style="background:yellow">Intended interpretation of Left<sub>&</sub>, "left argument of &"</span></td></tr>
	<tr><td align="right">~Connective<sub>&</sub>(P)&nbsp;</td><td>&#9500; Left<sub>&</sub>(P) is not well-formed</td></tr>
	<tr><td align="right">Right<sub>&</sub>(P & Q)&nbsp;</td><td>:= Q for all statements P, Q</td><td rowspan="3"><span style="background:yellow">Intended interpretation of Right<sub>&</sub>, , "right argument of &"</span></td></tr>
	<tr><td align="right">~Connective<sub>&</sub>(P)&nbsp;</td><td>&#9500; Right<sub>&</sub>(P) is not well-formed</td></tr>
</table>
<p>Note that Left<sub>&</sub>(P & Q & R) and Right<sub>&</sub>(P & Q & R) are not definable without the concept of mathematical collection &mdash; each of these has 
	two possible results, according to the uniform substitutions authorized by <i>associativity of &</i>.</p>
<p>We now have sufficient notation to define a predicate on <b>TruthValued</b>, for any inference rule seen so far, that evaluates to <i>true</i> for a statement P if and only if P matches the hypothesis of the inference rule.  For a syntactical 
	equivalance, we have two such predicates.  We expect these predicates to be typically distinct.</p>
<p>Let Leftmost<sub>&</sub> and Rightmost<sub>&</sub> be of type <b>TruthValued</b> <span style="position:relative; top: -2px">&#x2192;</span> <b>TruthValued</b>.  We define:</p>
<table align="center">
	<tr><td>~Connective<sub>&</sub>(P) &#9500; Leftmost<sub>&</sub>(P) := P</td></tr>
	<tr><td>Leftmost<sub>&</sub>(P & Q) := Leftmost<sub>&</sub>(P)</td></tr>
	<tr><td>~Connective<sub>&</sub>(P) &#9500; Rightmost<sub>&</sub>(P) := P</td></tr>
	<tr><td>Rightmost<sub>&</sub>(P & Q) := Rightmost<sub>&</sub>(Q)</td></tr>
</table><p>The above looks like an attempt at a recursive definition, suitable for use in a proof by induction.  The first two lines correspond to basis cases of an inductive proof.
	The second two lines are intended to eventually reach one of the basis cases.  We are, however, assuming that P & Q is not self-referential 
	when fully expanded.  (That is, in some sense we want P & Q to be a "well-founded" statement.  Statements constructed according to the rules sketched in our 
	overview of formal systems, will be "well-founded", but we do not have the notation to prove that.)</p>
<table align="right">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>Leftmost<sub>&</sub>((P & Q) & R)</td><td>Given</td></tr>
	<tr><td>2.</td><td>Leftmost<sub>&</sub>(P & Q)</td><td>Definition of Leftmost<sub>&</sub></td></tr>
	<tr><td>3.</td><td>Leftmost<sub>&</sub>(P)</td><td>Definition of Leftmost<sub>&</sub></td></tr>
	<tr><th colspan="3">Leftmost<sub>&</sub>((P & Q) & R) &#x21A6;<sub>Leftmost<sub>&</sub></sub> Leftmost<sub>&</sub>(P & Q) &#x21A6;<sub>Leftmost<sub>&</sub></sub> Leftmost<sub>&</sub>(P)</th></tr>
</table>
<table align="left">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>Leftmost<sub>&</sub>(P & (Q & R))</td><td>Given</td></tr>
	<tr><td>2.</td><td>Leftmost<sub>&</sub>(P)</td><td>Definition of Leftmost<sub>&</sub></td></tr>
	<tr><th colspan="3">Leftmost<sub>&</sub>(P & (Q & R)) &#x21A6;<sub>Leftmost<sub>&</sub></sub> Leftmost<sub>&</sub>(P)</th></tr>
</table>
<p>This is promising: no matter which of uniform substitutions authorized by <i>associativity of &</i> is used, evaluating Leftmost<sub>&</sub>(P & Q & R) will 
end up evaluating Leftmost<sub>&</sub>(P).  We have structurally similar calculations for Rightmost<sub>&</sub>.  This is a rationale for defining</p>
<table align="center">
	<tr><td>Leftmost<sub>&</sub>(P & Q & R) := Leftmost<sub>&</sub>(P)</td></tr>
	<tr><td>Rightmost<sub>&</sub>(P & Q & R) := Rightmost<sub>&</sub>(R)</td></tr>
</table>

<p>Next, let NotLeftmost<sub>&</sub> and NotRightmost<sub>&</sub> be of type <b>TruthValued</b> <span style="position:relative; top: -2px">&#x2192;</span> <b>TruthValued</b>.  We define:</p>
<table align="center">
	<tr><td>~Connective<sub>&</sub>(P) &#9500; NotLeftmost<sub>&</sub> is not well-formed</td><td rowspan="3"><span style="background:yellow">Intended interpretation of NotLeftmost<sub>&</sub></span>, "all clauses other than the left-most one of a conjunction"</td></tr>
	<tr><td>~Connective<sub>&</sub>(P) &#9500; NotLeftmost<sub>&</sub>(P & Q) := Q</td></tr>
	<tr><td>Connective<sub>&</sub>(P) &#9500; NotLeftmost<sub>&</sub>(P & Q) := NotLeftmost<sub>&</sub>(P) & Q</td></tr>
	<tr><td>~Connective<sub>&</sub>(P) &#9500; NotRightmost<sub>&</sub> is not well-formed</td><td rowspan="3"><span style="background:yellow">Intended interpretation of NotRightmost<sub>&</sub></span>, "all clauses other than the right-most one of a conjunction"</td></tr>
	<tr><td>~Connective<sub>&</sub>(Q) &#9500; NotRightmost<sub>&</sub>(P & Q) := P</td></tr>
	<tr><td>Connective<sub>&</sub>(Q) &#9500; NotRightmost<sub>&</sub>(P & Q) := P & NotRightmost<sub>&</sub>(Q)</td></tr>
</table>
<p>Again, the above looks like a recursive definition, with the same caveats as the prior one.  We presume we can use similar definitions for any other binary logical connective.</p>

<table align="right">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>Connective<sub>&</sub>(P)</td><td>Given</td></tr>
	<tr><td>2.</td><td>NotLeftmost<sub>&</sub>((P & Q) & R)</td><td>Given</td></tr>
	<tr><td>3.</td><td>NotLeftmost<sub>&</sub>(P & Q) & R</td><td><span style="background:yellow">Intended interpretation of NotLeftmost<sub>&</sub></span></td></tr>
	<tr><td>4.</td><td>(NotLeftmost<sub>&</sub>(P) & Q) & R</td><td><span style="background:yellow">Intended interpretation of NotLeftmost<sub>&</sub></span></td></tr>
	<tr><td>5.</td><td>NotLeftmost<sub>&</sub>(P) & (Q & R)</td><td>Associativity of &</td></tr>

</table>
<table align="left">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>Connective<sub>&</sub>(P)</td><td>Given</td></tr>
	<tr><td>2.</td><td>NotLeftmost<sub>&</sub>(P & (Q & R))</td><td>Given</td></tr>
	<tr><td>3.</td><td>NotLeftmost<sub>&</sub>(P) & (Q & R)</td><td><span style="background:yellow">Intended interpretation of NotLeftmost<sub>&</sub></span></td></tr>

</table>

<table align="right" style="clear:right">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>~Connective<sub>&</sub>(P)</td><td>Given</td></tr>
	<tr><td>2.</td><td>NotLeftmost<sub>&</sub>((P & Q) & R)</td><td>Given</td></tr>
	<tr><td>3.</td><td>NotLeftmost<sub>&</sub>(P & Q) & R</td><td><span style="background:yellow">Intended interpretation of NotLeftmost<sub>&</sub></span></td></tr>
	<tr><td>4.</td><td>Q & R</td><td><span style="background:yellow">Intended interpretation of NotLeftmost<sub>&</sub></span></td></tr>

</table>
<table align="left" style="clear:left">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>~Connective<sub>&</sub>(P)</td><td>Given</td></tr>
	<tr><td>2.</td><td>NotLeftmost<sub>&</sub>(P & (Q & R))</td><td>Given</td></tr>
	<tr><td>3.</td><td>Q & R</td><td><span style="background:yellow">Intended interpretation of NotLeftmost<sub>&</sub></span></td></tr>

</table>
<p>We have similar calculations for NotRightmost<sub>&</sub>.  Again, after confirming we get the same expression regardless of our choice of parenthesization for P & Q & R, we may define</p>
<table align="center" style="clear:both">
	<tr><td>Connective<sub>&</sub>(P) &#9500; NotLeftmost<sub>&</sub>(P & Q & R) := NotLeftmost<sub>&</sub>(P) & (Q & R)</td></tr>
	<tr><td>~Connective<sub>&</sub>(P) &#9500; NotLeftmost<sub>&</sub>(P & Q & R) := Q & R</td></tr>
	<tr><td>Connective<sub>&</sub>(R) &#9500; NotRightmost<sub>&</sub>(P & Q & R) := (P & Q) & NotRightmost<sub>&</sub>(R)</td></tr>
	<tr><td>~Connective<sub>&</sub>(R) &#9500; NotRightmost<sub>&</sub>(P & Q & R) := P & Q</td></tr>
</table>

<p>Now, let us consider what a predicate GeneralizedAssociativity<sub>&</sub>:<b>TruthValued</b> <span style="position:relative; top: -2px">&#x2192;</span> <b>TruthValues</b>, with intended 
	interpretation "syntactical generalized associativity applies" would have
	to satisfy, to both allow an inductive proof, and be true for our intended base case <i>associativity of &</i>.</p>
<table align="center">
	<tr><td>~Connective<sub>&</sub>(P) &#9500; ~GeneralizedAssociativity<sub>&</sub>(P)</td><td rowspan="5">Associativity of & [interpretation as predicate]</td></tr>
	<tr><td>~Connective<sub>&</sub>(P),~Connective<sub>&</sub>(Q) &#9500; ~GeneralizedAssociativity<sub>&</sub>(P & Q)</td></tr>
	<tr><td>~Connective<sub>&</sub>(P),~Connective<sub>&</sub>(Q),~Connective<sub>&</sub>(R) &#9500; GeneralizedAssociativity<sub>&</sub>(P & Q & R)</td></tr>
	<tr><th colspan="2">Want to derive</th></tr>
	<tr><td>GeneralizedAssociativity<sub>&</sub>(P & Q & R) &#9500; (P & Q & R &#x27DB; Leftmost<sub>&</sub>(P & Q & R) & NotLeftmost<sub>&</sub>(P & Q & R))</td><td rowspan="3">Expectation for generalized associativity of & [interpretation as predicate]</td></tr>
	<tr><td>GeneralizedAssociativity<sub>&</sub>(P & Q & R) &#9500; (P & Q & R &#x27DB; NotRightmost<sub>&</sub>(P & Q & R) & Rightmost<sub>&</sub>(P & Q & R))</td></tr>
	<tr><td>&#9500; GeneralizedAssociativity<sub>&</sub>(P & Q & R)</td></tr>
</table>
<table align="right">
	<tr><th></th><th>Inference rule</th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td></td><td>~Connective<sub>&</sub>(P)</td><td>Given</td></tr>
	<tr><td>2.</td><td></td><td>P & Q & R</td><td>Hypothesis</td></tr>
	<tr><td>3.</td><td></td><td>P & (Q & R)</td><td>Associativity of &</td></tr>
	<tr><td>4.</td><td></td><td>Leftmost<sub>&</sub>(P) & NotLeftmost<sub>&</sub>(P & (Q & R))</td><td>[Leftmost<sub>&</sub>(P)/P,NotLeftmost<sub>&</sub>(P & (Q & R))/Q & R] on (3) by (1)</td></tr>
	<tr><td>5.</td><td></td><td>Leftmost<sub>&</sub>(P & (Q & R)) & NotLeftmost<sub>&</sub>(P & (Q & R))</td><td>[Leftmost<sub>&</sub>(P & (Q & R))/Leftmost<sub>&</sub>(P)] on (4) by (1)</td></tr>
	<tr><td>6.</td><td>P & Q & R &#9500; Leftmost<sub>&</sub>(P & (Q & R)) & NotLeftmost<sub>&</sub>(P & (Q & R))</td><td></td><td>syntactical inference rule introduction (2),(5)</td></tr>
	<tr><th colspan="4">But the rationales for linking steps 2-6 are all syntactical or substitution equivalences, so</th></tr>
	<tr><td>6a.</td><td>P & Q & R &#x27DB; Leftmost<sub>&</sub>(P & (Q & R)) & NotLeftmost<sub>&</sub>(P & (Q & R))</td><td></td><td>syntactical inference rule introduction (2),(5)</td></tr>
</table>
<p>So we have two special cases of the generalized associativity conclusion (the other one has a very similar proof to the one sketched):</p>
<table>
	<tr><td>~Connective<sub>&</sub>(P) &#9500; (P & Q & R &#x27DB; Leftmost<sub>&</sub>(P & (Q & R)) & NotLeftmost<sub>&</sub>(P & (Q & R)))</td></tr>
	<tr><td>~Connective<sub>&</sub>(R) &#9500; (P & Q & R &#x27DB; NotRightmost<sub>&</sub>((P & Q) & R)) & Rightmost<sub>&</sub>((P & Q) & R)))</td></tr>
</table>
....
-->

<h2 id="excluded-middle" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px; clear:both">Law of Excluded Middle</h2>
<p>This classical logic tautology (always-true statement) degrades to a never-false statement in many other logics.  Key steps are incorrect for all of the non-classical logics we
	are considering.</p>
<p>For classical logic, we can downgrade a syntactical entailment &#9500; to a nonstrict logical implication &rArr;, by
	choosing any one hypothesis of the syntactical entailment and converting it to a single hypothesis
	that nonstrictly implies &rArr; the conclusion of the syntactical entailment.  (With sufficient infrastructure built out
	to mathematically model notation, this would be a deduction metatheorem.)  This fails for all of our truth table describable non-classical logics.</p>
<p>I will structure this to look like using the procedure of condensed detachment, developed by Carew Arthur Meredith in the 1950's, against <i>modus ponens</i>.  <i>Principia Mathematica</i>
	proceeds as follows:</p>
<table align="center">
	<tr><th></th><th>Inference Rule</th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &#9500; P &#x2228; P</td><td></td><td>Idempotence of &#x2228;</td></tr>
	<tr><td>2.</td><td></td><td>P &rArr; (P &#x2228; P)</td><td><span style="background:yellow">Downgrade &#9500; to &rArr;</span> in (1)</td></tr>
	<tr><td>3.</td><td>P &rArr; Q, Q &rArr; P &#9500; P &rArr; P</td><td></td><td>apply R &#x21A6; P to Transitivity of implication</td></tr>
	<tr><td>4.</td><td>P &rArr; (P &#x2228; P), (P &#x2228; P) &rArr; P &#9500; P &rArr; P</td><td></td><td>apply Q &#x21A6; P &#x2228; P to (3)</td></tr>
	<tr><td>5.</td><td>(P &#x2228; P) &rArr; P &#9500; (P &rArr; (P &#x2228; P)) &rArr; (P &rArr; P)</td><td></td><td><span style="background:yellow">Downgrade &#9500; to &rArr;</span> in (4)</td></tr>
	<tr><td>6.</td><td></td><td>((P &#x2228; P) &rArr; P) &rArr; ((P &rArr; (P &#x2228; P)) &rArr; (P &rArr; P))</td><td><span style="background:yellow">Downgrade &#9500; to &rArr;</span> in (5)</td></tr>
	<tr><td>7.</td><td></td><td>(P &#x2228; P) &rArr; P</td><td><span style="background:yellow">Downgrade &#9500; to &rArr;</span> in Idempotence of &#x2228;</td></tr>
	<tr><td>8.</td><td></td><td>(P &rArr; (P &#x2228; P)) &rArr; (P &rArr; P)</td><td><i>modus ponens</i> on (6) and (7)</td></tr>
	<tr><td>9.</td><td></td><td>P &rArr; P</td><td><i>modus ponens</i> on (2) and (8)</td></tr>
	<tr><td>10.</td><td></td><td>~P &#x2228; P</td><td>Definition of &rArr;</td></tr>
</table>
<p>The above <b>proof</b> of the principle of bivalence, is not remotely intuitive.  We <b>could</b> have done this like the earlier exercises documenting the 
	semantic consequences of the descriptions of logical not ~, logical and &, and logical or &#x2228; for the various logics.
	The object, however, is to minimize the semantic consequences we need to "get started".</p>
<table align="center">
	<tr><th colspan=2>Classical logic</th></tr>
	<tr><th></th><th>Name</th></tr>
	<tr><td align="center">&#9500; ~P &#x2228; P</td><td align="left">Law of the Excluded Middle</td></tr>
	<tr><td align="center">&#9500; P &rArr; P</td><td align="left"></td></tr>
	<tr><td align="center">&#9500; P &hArr; P</td><td align="left">Reflexivity of &hArr;</td></tr>
</table>
<p>The classical logic proof of the reflexivity of &hArr;, is left as an exercise.</p>
<p>Recall that the intended interpretation of <i>true</i> and <i>false</i> for Intuitionistic logic is proof existence.
	That is, the intended interpretation of <i>true</i> a truth-valued statement P is that P is provable,
	and the intended interpretation of <i>false</i> for P, is that ~P is provable.
	While G&ouml;del's Second Incompleteness Theorem post-dates Intuitionistic logic by decades, 
	it confirms that <i>~P &#x2228; P</i> is <b>not</b> a tautology for Intuitionistic logic,
	even though it does not use nonclassical truth values.  The possibility of not having a proof for either
	P or ~P, looks like Kleene's strong three-valued logic's intended interpretation of <i>unknown</i>.</p>
<p>The rationale for Intuitionistic logic rejecting removing double negations, is that allows proving the Law of the Excluded Middle by proof by contradiction.  Generally speaking,
	if a truth-valued expression A is provable in classical logic, then ~~A is provable in Intuitionistic logic.</p>
<p><i>Principia Mathematica</i> uses the law of the excluded middle, to derive both double negation addition and removal syntactically (for classical logic),
	rather than the natural language rationale I referenced.</p>
<blockquote>Intuitionistic logic can be described as classical logic without [Law of Excluded Middle] (or the principle of double negation (~~&phi; &rArr; &phi;)),
	but with the classical law of contradiction ((&phi; &rArr; &psi;) &rArr; ((&phi; &rArr; ~&psi;) &rArr; ~&phi;))
	 and <i>ex falso quodlibet</i> (~&phi; &rArr; (&phi; &rArr; &psi;)) <nobr>&mdash; <a href="https://plato.stanford.edu/entries/disjunction/">Stanford Encyclopedia of Philosophy</a></nobr></blockquote>
<p>So while Intuitionistic logic does not have a truth-functional description, it is close enough to classical logic that we can use it as an option for building out set theory.</p>	
<p>Note that neither the <i>principle of bivalence</i>, nor <i>commutativity of &#x2228;</i>, was used (even implicitly) in deriving the Law of the Excluded Middle. That is,
	the <i>principle of bivalence</i> is <b>provable</b> in classical logic; if we had forgotten to translate it from English, we would recover it here.</p>

<h2 id="translating-truth-tables" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px; clear:both">Translating to and from truth tables</h2>
<p>We are now in a position to translate between the truth table descriptions of the logics we are considering, and the symbolic notation.  The critical inference rules are: principle of bivalence/trivalence/tetravalence, 
	principle of non-contradiction,  the left and right distributivity rules for logical and & and logical or &#x2228;, proof by cases, and the substitution validity of commutativity of logical and & and logical or &#x2228;.</p>
<ul>
	<li>principle of bivalence/trivalence/tetravalence: translated from natural language.  Principle of bivalence has a known classical logic proof.</li>
	<li>principle of non-contradiction: translated from natural language.</li>
	<li>the left and right distributivity rules for logical and & and logical or &#x2228; .  We need all eight, but most of these rules are only proven so far for classical logic.</li>
	<li>Proof by cases.  Our proof required right distributivity of &#x2228; over &, so we have this proven for most of our logics; Lisp/Prolog is the exception.</li>
	<li>Commutativity of logical and & and logical or &#x2228;.  We have this for five of the logics we are interested in.</li>
	<li>Downgrade &#9500; to &rArr; : We have this for classical logic <b>only</b>.</li>
</ul>
<p>According to the intended interpretation for <i>A</i> &#x21A6; <i>true</i>, etc., it appears that once a non-classical truth-valued expression <i>A</i> is known to evaluate to 
	any given truth value, that all of the logic-relevant <i>A</i> &#x21A6; <i>true</i>, etc. have classical truth values (exactly one <i>true</i>).  That suggests 
	we should take the principle of trivalence/tetravalence to be a <b>classical</b> logic statement, even though it is about a nonclassical logic.  We also see that we need the 
	A &#x21A6; <i>unknown</i>, etc. notation to even represent the non-classical logics enough to proceed with the (nearly) minimal undefined terms buildout.</p>
<table align="left" border="0" cellspacing="0" cellpadding="2" style="margin-right: 1em; clear:left">
	<tr align="center"><th colspan=3>Classical logic</th></tr>
	<tr align="center"><th>A</th><th>B</th><th>A &#x2228; B</th></tr>
	<tr align="center" style="background:#FFDDDD"><td><i>false</i></td><td><i>false</i></td><td><i>false</i></td></tr>
	<tr align="center" style="background:#DDFFDD"><td><i>false</i></td><td><i>true</i></td><td><i>true</i></td></tr>
	<tr align="center" style="background:#DDFFDD"><td><i>true</i></td><td><i>false</i></td><td><i>true</i></td></tr>
	<tr align="center" style="background:#DDDDFF"><td><i>true</i></td><td><i>true</i></td><td><i>true</i></td></tr>
</table>
<table align="right" border="0" cellspacing="0" cellpadding="2" style="margin-right: 1em; clear:right">
	<tr><th colspan="2">Classical logic</th></tr>
	<tr><td align="right">(A &#x21A6; <i>false</i>),(B &#x21A6; <i>false</i>) &#9500;&nbsp;</td><td>(A &#x2228; B) &#x21A6; <i>false</i></td></tr>
	<tr><td align="right">(A &#x21A6; <i>false</i>),(B &#x21A6; <i>true</i>) &#9500;&nbsp;</td><td>(A &#x2228; B) &#x21A6; <i>true</i></td></tr>
	<tr><td align="right">(A &#x21A6; <i>true</i>),(B &#x21A6; <i>false</i>) &#9500;&nbsp;</td><td>(A &#x2228; B) &#x21A6; <i>true</i></td></tr>
	<tr><td align="right">(A &#x21A6; <i>true</i>),(B &#x21A6; <i>true</i>) &#9500;&nbsp;</td><td>(A &#x2228; B) &#x21A6; <i>true</i></td></tr>
	<tr><td align="right">(A &#x2228; B) &#x21A6; <i>false</i> &#9500;&nbsp;</td><td>(A &#x21A6; <i>false</i>) & (B &#x21A6; <i>false</i>)</td></tr>
	<tr><td align="right">(A &#x2228; B) &#x21A6; <i>true</i> &#9500;&nbsp;</td><td>((A &#x21A6; <i>false</i>) & (B &#x21A6; <i>true</i>)) &#x2228; ((A &#x21A6; <i>true</i>) & (B &#x21A6; <i>false</i>)) &#x2228; ((A &#x21A6; <i>true</i>) & (B &#x21A6; <i>true</i>))</td></tr>
</table>
<p>To check that we understand how to translate between the truth table and the symbolic notations, we are going to derive (left) disjunction introduction, for classical logic.  Both the left side truth table, and the right side Gentzen-style notation, describe classical logical or 
	&#x2228; .  To verify using the truth table, we just visually check that for all rows with  <i>A true</i>, <i>A</i> &#x2228; <i>B</i> is <i>true</i>.  Of the six logics we are interested in, 
	the only one which fails the truth table inspection is Kleene's weak three-valued logic.</p>
<table align="right" style="clear:right">
	<tr><th colspan="3">Classical logic</th></tr>
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P</td><td>Given</td></tr>
	<tr><td>2.</td><td>~Q &#x2228; Q</td><td>Law of the Excluded Middle</td></tr>
	<tr><td>3.</td><td>P & (~Q &#x2228; Q)</td><td>Conjunction introduction on (1),(2)</td></tr>
	<tr><td>4.</td><td>(P & ~Q) &#x2228; (P & Q)</td><td>Left distributivity of & over &#x2228;</td></tr>
	<tr><td>5.</td><td>(P & ~Q) &rArr; (P &#x2228; Q)</td><td>Downgrade definition of &#x2228; from &#9500; to &rArr;</td></tr>
	<tr><td>6.</td><td>(P & Q) &rArr; (P &#x2228; Q)</td><td>Downgrade definition of &#x2228; from &#9500; to &rArr;</td></tr>
	<tr><td>7.</td><td>P &#x2228; Q</td><td>Proof by cases on (5),(6),(4)</td></tr>
</table><p>The derivation of right disjunction introduction for classical logic, is very similar and left as an exercise.  The truth table inspection is failed for both Kleene's weak three-valued logic, 
	and Lisp/Prolog logic.  The derivations for the non-classical logics we are interested in, are also left as exercises.</p>
<table align="center" style="clear:both">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &#9500; P &#x2228; Q</td><td>(left) Disjunction introduction</td><td>Kleene weak</td><td>some paraconsistent</td></tr>
	<tr><td align="center">Q &#9500; P &#x2228; Q</td><td>(right) Disjunction introduction</td><td>Kleene weak, Lisp/Prolog</td><td>some paraconsistent</td></tr>
</table>
<table align="right">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>Q &#x2228; P</td><td>(left) disjunction introduction</td></tr>
	<tr><td>3.</td><td>P &#x2228; Q</td><td>Commutativity of &#x2228;</td></tr>
</table>
<p>An alternate derivation of right disjunction introduction, uses both left disjunction introduction and commutativity of &#x2228;.  This explains its failure in 
	both Kleene's weak three-valued logic (like left disjunction introduction), and in Lisp/Prolog logic (like commutativity of &#x2228;). </p>

<p id="principle-of-explosion">Disjunction introduction, i.e. introducing a "logical or" statement as a temporary statement, is behind a number of paradoxes.  As a brute fact, the expansion of Q need have nothing to do with the expansion of P.
	A closely related rewrite gives a semantic paradox of classical logic, the principle of explosion: a false statement nonstrictly implies any statement (regardless of relevance).  Also known as (Latin)
	 <i>ex falso quodlibet</i>.</p>
<table align="center">
		<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
		<tr><td>1.</td><td>~P</td><td>Given</td></tr>
		<tr><td>2.</td><td>~P &#x2228; Q</td><td>Disjunction introduction</td></tr>
		<tr><td>3.</td><td>P &rArr; Q</td><td>Definition of &rArr;</td></tr>
</table>	
<table align="center">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">~P &#9500; P &rArr; Q</td><td align="left">Principle of explosion</td><td align="left">Kleene weak</td><td>some paraconsistent</td></tr>
</table>
	<h2 id="commutativity-or-lisp" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Repairing commutativity of &#x2228; for Lisp/Prolog logic</h2>
	<p>While the Law of the Excluded Middle, ~P &#x2228; P, is not itself a tautology for the other five truth-table describable logics we are considering,
		it is still important: it passes through the non-classical truth values <i>unknown</i> and <i>contradiction</i> unchanged.  That is, we can use it 
		to formally detect whether a truth value is classical.  Visually checking that all rows for which a statement A is true, have a classical truth value for the propositional variable P or Q, 
		corresponds to using proof by cases, where the nonstrict implications are formed by conjunction elimination followed by disjunction introduction.</p>
	<p>For the following exercise, assume that the logic used to manipulate the A <i>true</i>, etc. statements is classical logic, regardless of the non-classical logic 
	   being analyzed.  This is how we are going to complete the missing proofs for the non-classical truth table described logics.</p>
	<table align="center">
		<tr><th></th><th>Name</th><th>Useful for which of our logics?</th><th>Fails for which of our logics?</th></tr>
		<tr><td align="center">P &#x2228; Q &#9500; ~P &#x2228; P</td><td style="background: yellow">Left classical truth value of &#x2228;</td><td>Lisp/Prolog, Weak Kleene</td><td>Belnap, Strong Kleene, Franci</td></tr>
		<tr><td align="center">~P &#x2228; Q &#9500; ~P &#x2228; P</td><td style="background: yellow">Left classical truth value of &#x2228;</td><td>Lisp/Prolog, Weak Kleene</td><td>Belnap, Strong Kleene, Franci</td></tr>
		<tr><td align="center">P &#x2228; Q &#9500; ~Q &#x2228; Q</td><td style="background: yellow">Right classical truth value of &#x2228;</td><td>Weak Kleene</td><td>Lisp/Prolog</td></tr>
		<tr><td align="center">~P &#x2228; Q &#9500; ~Q &#x2228; Q</td><td style="background: yellow">Right classical truth value of &#x2228;</td><td>Weak Kleene</td><td>Lisp/Prolog</td></tr>
		<tr><td align="center">P &#x2228; Q, ~P &#9500; ~Q &#x2228; Q</td><td style="background: yellow">Right classical truth value of &#x2228;</td><td>Lisp/Prolog</td><td></td></tr>
		<tr><td align="center">~P &#x2228; Q, P &#9500; ~Q &#x2228; Q</td><td style="background: yellow">Right classical truth value of &#x2228;</td><td>Lisp/Prolog</td><td></td></tr>
		<tr><td align="center">~(P & Q) &#9500; ~P &#x2228; P</td><td style="background: yellow">Left classical truth value of ~(&)</td><td>Lisp/Prolog, Weak Kleene</td><td>Belnap, Strong Kleene, Franci</td></tr>
		<tr><td align="center">~(~P & Q) &#9500; ~P &#x2228; P</td><td style="background: yellow">Left classical truth value of ~(&)</td><td>Lisp/Prolog, Weak Kleene</td><td>Belnap, Strong Kleene, Franci</td></tr>
		<tr><td align="center">~(P & Q) &#9500; ~Q &#x2228; Q</td><td style="background: yellow">Right classical truth value of ~(&)</td><td>Weak Kleene</td><td>Lisp/Prolog</td></tr>
		<tr><td align="center">~(~P & Q) &#9500; ~Q &#x2228; Q</td><td style="background: yellow">Right classical truth value of ~(&)</td><td>Weak Kleene</td><td>Lisp/Prolog</td></tr>
		<tr><td align="center">~(P & Q), ~P &#9500; ~Q &#x2228; Q</td><td style="background: yellow">Right classical truth value of ~(&)</td><td>Lisp/Prolog</td><td></td></tr>
		<tr><td align="center">~(~P & Q), P &#9500; ~Q &#x2228; Q</td><td style="background: yellow">Right classical truth value of ~(&)</td><td>Lisp/Prolog</td><td></td></tr>
	</table>
	<p>Other inference rules of this kind can be obtained by using the definition of &rArr;, and applying the uniform substitution [~Q/Q].  We are 
		not using De Morgan's law to derive the not-and rules, as that is one of the key inference rules we want to find alternate proofs for.</p>
	<p>Our immediate use, is the following, left as an exercise. Informally, if we know that in Lisp/Prolog logic that the propositional variables 
		P, Q both have classical truth values (<i>true</i>, or <i>false</i>), then the substitutions [Q & P/P & Q] and [Q &#x2228; P/P &#x2228; Q] 
		are valid because they are actually classical logic substituions.</p>
	</p>
	<table align="center">
		<tr><th colspan="2">Lisp/Prolog</th></tr>
		<tr><th></th><th>Name</th></tr>
		<tr><td align="center">~P &#x2228; P, ~Q &#x2228; Q &#9500; (A &#x27DB; A[Q & P/P & Q])</td><td>Commutativity of &, Lisp/Prolog</td></tr>
		<tr><td align="center">~P &#x2228; P, ~Q &#x2228; Q &#9500; (A &#x27DB; A[P & Q/Q & P])</td><td>Commutativity of &, Lisp/Prolog</td></tr>
		<tr><td align="center">~P &#x2228; P, ~Q &#x2228; Q &#9500; (A &#x27DB; A[Q &#x2228; P/P &#x2228; Q])</td><td>Commutativity of &#x2228;, Lisp/Prolog</td></tr>
		<tr><td align="center">~P &#x2228; P, ~Q &#x2228; Q &#9500; (A &#x27DB; A[P &#x2228; Q/Q &#x2228; P])</td><td>Commutativity of &#x2228;, Lisp/Prolog</td></tr>
	</table>
	<p>Since the usual given for <i>taking the contrapositive</i> also syntactically entails that the antecedent i.e. hypothesis has a classical truth value, we merely need, as an extra given, 
	that the consequent i.e. consequence also has a classical truth value.  Modifying the typical proofs to work for Lisp/Prolog logic are left as an exercise:</p>
	<table id="repair-lisp-prolog-modus-tollens" align="center">
		<tr><th colspan="2">Lisp/Prolog</th></tr>
		<tr><th></th><th>Name</th></tr>
		<tr><td align="center">~P &rArr; Q, ~Q &#x2228; Q &#9500; ~Q &rArr; P</td><td align="left">taking contrapositive, Lisp/Prolog</td></tr>
		<tr><td align="center">~P &rArr; ~Q, ~Q &#x2228; Q &#9500; Q &rArr; P</td><td align="left">taking contrapositive, Lisp/Prolog</td></tr>
		<tr><td align="center">~P &rArr; Q, ~Q &#x2228; Q &#9500; ~Q &rArr; P</td><td align="left">taking contrapositive, Lisp/Prolog</td></tr>
		<tr><td align="center">~P &rArr; ~Q, ~Q &#x2228; Q &#9500; Q &rArr; P</td><td align="left">taking contrapositive, Lisp/Prolog</td></tr>
		<tr><td align="center">P &rArr; Q, ~Q &#9500; ~P</td><td align="left"><i>modus tollens</i></td></tr>
		<tr><td align="center">P &#x2228; Q, ~Q, &#9500; P</td><td align="left"><span style="background:yellow">(right)</span> Or elimination</td></tr>
	</table>
	<p>We also have:</p>
	<table align="center">
		<tr><th></th><th>Inference Rule</th><th>Rationale</th></tr>
		<tr><td>1.</td><td>~P &#x2228; P</td><td>Given</td></tr>
		<tr><td>2.</td><td>~P &#x2228; P, ~P &#x2228; P &#9500; (A &#x27DB; A[P &#x2228; ~P/~P &#x2228; P])</td><td>apply [~P/Q] to commutativity of &#x2228;, Lisp/Prolog</td></tr>
		<tr><td>3.</td><td>~P &#x2228; P &#9500; (A &#x27DB; A[P &#x2228; ~P/~P &#x2228; P])</td><td>Idempotence of hypotheses of &#9500; on (1)</td></tr>
		<tr><td>4.</td><td>~P &#x2228; P &#x27DB; (~P &#x2228; P)[P &#x2228; ~P/~P &#x2228; P]</td><td>syntactical entailment on (3), (1)</td></tr>
		<tr><td>3.</td><td>~P &#x2228; P &#x27DB; P &#x2228; ~P</td><td>evaluate substitution in (4)</td></tr>
	</table>
	<p>That is, the Law of the Excluded Middle <i>~P &#x2228; P</i> is self-sufficient for using <i>commutativity of &#x2228;</i> on itself, for Lisp/Prolog logic, to its more 
		usual representation in the literature, <i>P &#x2228; ~P</i></p>

<h2 align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Revisiting transitivity of implication</h2>
<p>We are now in a position to re-implement, with symbolic logic, the truth-table calculations about <i>transitivity of implication</i> for our 
	non-classical logics of interest.  To do this check for classical logic, would be circular reasoning -- we used <i>transitivity of implication</i> to 
	derive <i>constructive dilemma</i>.</p>
<table align="left">
	<tr><th colspan="3">Classical logic</th></tr>
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &rArr; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>Q &rArr; R</td><td>Given</td></tr>
	<tr><td>3.</td><td>~P &#x2228; Q</td><td>Definition of &rArr;</td></tr>
	<tr><td>4.</td><td>~Q &#x2228; R</td><td>Definition of &rArr;</td></tr>
	<tr><td>5.</td><td>((~P &#x21A6; <i>false</i>) & (Q &#x21A6; <i>true</i>)) &#x2228; ((~P &#x21A6; <i>true</i>) & (Q &#x21A6; <i>true</i>)) &#x2228; ((~P &#x21A6; <i>true</i>) & (Q &#x21A6; <i>false</i>))</td><td>Apply [~P/P] to Invert (P &#x2228; Q) &#x21A6; <i>true</i> (Kleene's weak three-valued logic)</td></tr>
	<tr><td>6.</td><td>((~Q &#x21A6; <i>false</i>) & (R &#x21A6; <i>true</i>)) &#x2228; ((~Q &#x21A6; <i>true</i>) & (R &#x21A6; <i>true</i>)) &#x2228; ((~Q &#x21A6; <i>true</i>) & (R &#x21A6; <i>false</i>))</td><td>Apply [~Q/P,R/Q] to Invert (P &#x2228; Q) &#x21A6; <i>true</i> (Kleene's weak three-valued logic)</td></tr>
	<tr><td>7.</td><td>(((~P &#x21A6; <i>false</i>) & (Q &#x21A6; <i>true</i>)) &#x2228; ((~P &#x21A6; <i>true</i>) & (Q &#x21A6; <i>true</i>)) &#x2228; ((~P &#x21A6; <i>true</i>)& (Q &#x21A6; <i>false</i>)))<br>& (((~Q &#x21A6; <i>false</i>) & (R &#x21A6; <i>true</i>)) &#x2228; ((~Q &#x21A6; <i>true</i>) & (R &#x21A6; <i>true</i>)) &#x2228; ((~Q &#x21A6; <i>true</i>) & (R &#x21A6; <i>false</i>)))</td><td>Conjunction introduction on (5),(6)</td></tr>
</table>
<p>The general strategy, is to start with the translations of the truth table descriptions for the givens, then rearrange into a very large logical or of 
	logical and clauses, then apply proof by cases to verify the conclusion holds.  As an example, let's start to work this for Kleene's weak three-valued logic. (This will also
	represent the circular reasoning, for checking classical logic.)</p>
<table align="right">
	<tr><th colspan="2">(P &rArr; Q) &#x21A6; <i>true</i></th></tr>
	<tr><th>P</th><th>Q</th></tr>
	<tr><td><i>true</i></td><td><i>true</i></td></tr>
	<tr><td><i>false</i></td><td><i>true</i></td></tr>
	<tr><td><i>false</i></td><td><i>false</i></td></tr>
</table>	
<table align="right" style="clear:right">
	<tr><th colspan="4">((P &rArr; Q) & (Q &rArr; R)) &#x21A6; <i>true</i></th></tr>
	<tr><th>P</th><th>Q</th><th>R</th><th>P &rArr; R</th></tr>
	<tr><td><i>true</i></td><td><i>true</i></td><td><i>true</i></td><td><i>true</i></td></tr>
	<tr><td><i>false</i></td><td><i>true</i></td><td><i>true</i></td><td><i>true</i></td></tr>
	<tr><td><i>false</i></td><td><i>false</i></td><td><i>true</i></td><td><i>true</i></td></tr>
	<tr><td><i>false</i></td><td><i>false</i></td><td><i>false</i></td><td><i>true</i></td></tr>
</table>	
<p>After the sixth step, the full details needed for an explicit symbolic logic proof are very verbose.  If we did not have the shorter truth table formatted 
	calculation, our strategy would be:</p>
<ul style="clear:left">
<li>Rearrange the seventh step, with distributivity and associativity inference rules, to a logical or &#x2228; 
	of nine propositions that are themselves each a logical and & of four propositions.  (There are generalized associativity principles that 
	allow suppressing the parentheses as "unimportant", but we have not proven them.)</li>
<li>For each of the nine propositions, use them as hypotheses to either:
	<ul>
		<li>Prove that the case is actually false, which enables removal by or-elimination, or</li>
		<li>Introduce a syntactical entailment for use in constructive dilemma, to reduce the syntactical complexity of the case.  It is this reduction 
			that will <i>transitivity of implication</i>, causing circular reasoning for classical logic.</li>
	</ul>
</li>
<li>For each surviving case, verify what the truth value of ~P &#x2228; R i.e. P &rArr; R, is.  If all surviving cases have this <i>true</i>, 
	then we have <i>transitivity of implication</i> for that logic.</li>
</ul>
<p>For emphasis:</p>
<ul>
	<li>The process of copying only consistent rows (where Q is equal in both the P &rArr; Q and Q &rArr; R reference table copies),
		has eliminated five of the nine cases as false, and also applied the required syntactical complexity reduction.</li>
	<li>Each row corresponds to a proposition that is a logical and & of three propositions representing the truth values 
		of the propositional variables.</li>
	<li>The enumeration of the rows, corresponds to a logical or &#x2228; of the propositions represented by each row.</li>
</ul>

<!-- restart editing -->

<h2 id="transitivity-of-iff" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Transitivity of &hArr;</h2>
<table align="right">
	<tr><th colspan=3>Transitivity of &hArr;</th></tr>
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &hArr; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>Q &hArr; R</td><td>Given</td></tr>
	<tr><td>3.</td><td>(P &rArr; Q) & (Q &rArr; P)</td><td>Definition of &hArr; on (1)</td></tr>
	<tr><td>4.</td><td>(Q &rArr; R) & (R &rArr; Q)</td><td>Definition of &hArr; on (2)</td></tr>
	<tr><td>5.</td><td>P &rArr; Q</td><td>Conjunction elimination on (3)</td></tr>
	<tr><td>6.</td><td>Q &rArr; R</td><td>Conjunction elimination on (4)</td></tr>
	<tr><td>7.</td><td>P &rArr; R</td><td>Transitivity of implication on (5),(6)</td></tr>
	<tr><td>8.</td><td>Q &rArr; P</td><td>Conjunction elimination on (3)</td></tr>
	<tr><td>9.</td><td>R &rArr; Q</td><td>Conjunction elimination on (4)</td></tr>
	<tr><td>10.</td><td>R &rArr; P</td><td>Transitivity of implication on (9),(8)</td></tr>
	<tr><td>11.</td><td>P &hArr; R</td><td>Definition of &hArr; on (7),(10)</td></tr>
</table>
<table align="left">
	<tr><th colspan=3>Commutativity of &hArr;</th></tr>
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &hArr; Q</td><td>Given</td></tr>
	<tr><td>2.</td><td>(P &rArr; Q) & (Q &rArr; P)</td><td>Definition of &hArr; on (1)</td></tr>
	<tr><td>3.</td><td>(Q &rArr; P) & (P &rArr; Q)</td><td>Commutativity of & on (2)</td></tr>
	<tr><td>4.</td><td>Q &hArr; P</td><td>Definition of &hArr; on (3)</td></tr>
</table>
<p>The usual formal proof of transitivity of &hArr; , fails for Belnap's four-valued logic.  Unlike transitivity of &rArr;, transitivity of &hArr; can be repaired, using the Law of the Excluded Middle 
	as a classical truth value detector.</p>
<p>Exercise: We have the following as semantic consequences:</p> 
<table align="center">
	<tr><th></th><th>Name</th><th>Useful for which of our logics?</th></tr>
	<tr><td align="center">P &hArr; Q, ~P &#x2228; P &#9500; ~Q &#x2228; Q</td><td style="background: yellow">Propagation of classical truth value by &hArr;</td><td>Belnap</td></tr>
	<tr><td align="center">P &hArr; Q, ~Q &#x2228; Q &#9500; ~P &#x2228; P</td><td style="background: yellow">Propagation of classical truth value by &hArr;</td><td>Belnap</td></tr>
</table>
<p>The two semantic consequences are related by commutativity of &hArr;.</p>
<p>The net effect is that if any of the three propositional variables in the statement of transitivity of &hArr; are known to be classical truth values, then all three are.</p>
<table align="center">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th></tr>
	<tr><td align="center">P &hArr; Q  &#9500; Q &hArr; P</td><td align="left">Commutativity of &hArr;</td><td align="left">None</td></tr>
	<tr><td align="center">P &hArr; Q, Q &hArr; R  &#9500; P &hArr; R</td><td align="left">Transitivity of &hArr;</td><td align="left">Belnap</td></tr>
</table>
<p>The proofs of the following are left as an exercise:</p>
<table align="center">
	<tr><th></th><th>Name</th><th>Useful for which of our logics?</th></tr>
	<tr><td align="center">~P &#x2228; P &#9500; P &hArr; P</td><td align="left">Reflexivity of &hArr;, non-classical</td><td>All except classical</td></tr>
	<tr><td align="center">~P &#x2228; P, P &hArr; Q, Q &hArr; R &#9500; P &hArr; R</td><td align="left">Transitivity of &hArr;, Belnap</td><td align="left">Belnap</td></tr>
	<tr><td align="center">~Q &#x2228; Q, P &hArr; Q, Q &hArr; R &#9500; P &hArr; R</td><td align="left">Transitivity of &hArr;, Belnap</td><td align="left">Belnap</td></tr>
	<tr><td align="center">~R &#x2228; R, P &hArr; Q, Q &hArr; R &#9500; P &hArr; R</td><td align="left">Transitivity of &hArr;, Belnap</td><td align="left">Belnap</td></tr>
</table>

<h2 id="commutativity-of-implication" align="center" style="margin-bottom: 0in; line-height: 100%; font-size: 14px">Commutativity of Implication [sic]</h2>
<p><i>Principia Mathematica</i> also suggests considering the following (*2&middot;04):</p>
<table align="center">
	<tr><th></th><th>Proposition</th><th>Rationale</th></tr>
	<tr><td>1.</td><td>P &rArr; (Q &rArr; R)</td><td>Given</td></tr>
	<tr><td>2.</td><td>~P &#x2228; (Q &rArr; R)</td><td>Definition of &rArr;</td></tr>
	<tr><td>3.</td><td>~P &#x2228; (~Q &#x2228; R)</td><td>Definition of &rArr;</td></tr>
	<tr><td>4.</td><td>(~P &#x2228; ~Q) &#x2228; R</td><td>Associativity of &#x2228;</td></tr>
	<tr><td>5.</td><td>(~Q &#x2228; ~P) &#x2228; R</td><td>Commutativity of &#x2228;</td></tr>
	<tr><td>6.</td><td>~Q &#x2228; (~P &#x2228; R)</td><td>Associativity of &#x2228;</td></tr>
	<tr><td>7.</td><td>~Q &#x2228; (P &rArr; R)</td><td>Definition of &rArr;</td></tr>
	<tr><td>8.</td><td>Q &rArr; (P &rArr; R)</td><td>Definition of &rArr;</td></tr>
</table>
<p>This is known either as <i>commutativity of implication</i> (in spite of the change crossing a parenthesized expression),
	or the generic "law of permutation" (of what?).</p>
<p>We do not yet have the formal machinery to prove the rearrangement principle, that would compress the fourth
	through sixth steps into one step.</p>
<table align="center">
	<tr><th></th><th>Name</th><th>Fails for which of our logics?</th><th>Fails for other logics?</th></tr>
	<tr><td align="center">P &rArr; (Q &rArr; R) &#9500; Q &rArr; (P &rArr; R)</td><td align="left">Commutativity of implication</td><td align="left">Lisp/Prolog</td><td>None</td></tr>
</table>

<p align="right">Next: <a href="./SubatomicPhysicsOfMath_IsMemberOf.html">description of &#x2208;, "is member of"</a></p>
</body>
</html>